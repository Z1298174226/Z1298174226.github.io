{"meta":{"title":"倾听枫声","subtitle":"lex-zhao","description":"生活的理想是为了理想的生活","author":"倾听枫声","url":"http://www.lex-zhao.xyz"},"pages":[{"title":"categories","date":"2017-05-03T02:49:12.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/categories/index.html","keywords":"","text":""},{"title":"","date":"2017-07-26T02:16:05.809Z","comments":true,"permalink":"http://www.lex-zhao.xyz/about/index.html","keywords":"","text":"Hello，欢迎来到lex-zhao，这是由倾听枫声管理的blog，主要记录一些算法实现、程序设计以及各种技术和非技术的相关内容。更多文章将在Archives中呈现。 初衷是希望有这样一个小小空间，可以把自己平时学习过程中积累的新知也好，感悟也罢，亦或是犯过的错误记录下来，时时翻看，聚沙成塔。"},{"title":"Tagcloud","date":"2017-05-03T01:46:02.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/tags/index.html","keywords":"","text":""}],"posts":[{"title":"canPartitionKSubsets","slug":"canPartitionKSubsets","date":"2017-11-23T01:54:05.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/11/23/canPartitionKSubsets/","text":"拿出以下三道题来进行对比和总结。 560. Subarray Sum Equals K 523. Continuous Subarray Sum 209. Minimum Size Subarray Sum 713. Subarray Product Less Than K 前三道题看到求连续子序列和问题，条件反射想到了Two Pointer，同时通过构建Map，可以以空间换时间的方式进一步降低算法复杂度。 map put进初值 求子序列长度 1map.put(0, -1) 求序列个数 1map.put(0, 1) 这几道题可以进一步做引申，分为两种情况： 和为k 12345678for(int num : nums) &#123; result += num; Integer pre = map.get(result - k); if(pre != null) &#123; ... &#125; map.put(result, map.getOrDefault(result, 0) + 1);&#125; 和为 m * k（k = 1， 2， 3， …) 1234567891011for(int num : nums) &#123; result += num; result %= k; Integer pre = map.get(result); if(pre != null) &#123; ... &#125; map.put(...);&#125;` 1234567891011121314public static int subarraySum(int[] nums, int k) &#123; Map&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;(); int result = 0; int resultSum = 0; map.put(0, 1); for(int i = 0; i &lt; nums.length; i++) &#123; resultSum += nums[i]; Integer pre = map.get(resultSum - k); if(pre != null) &#123; result += pre; &#125; map.put(resultSum, map.getOrDefault(resultSum, 0) + 1); &#125; return result; &#125; ======================= 713题是一道DP，采用带备忘自顶向下的方法，思路比较清晰。同时因为各子序列间不能有重叠项，因此需要引入boolean类型数组作标记。这道题同样可以引申为两种情况： k = 2(变成了一道01背包问题） 12345678910111213141516public static boolean canPartitionKSubsets(int[] nums) &#123; int sum = 0; for(int num : nums) sum += num; if(sum % 2 != 0) return false; sum /= 2; int[] dp = new int[sum + 1]; Arrays.fill(dp, Integer.MAX_VALUE); dp[0] = 0; for(int i = 0; i &lt; nums.length; i++) &#123; for(int j = sum; j &gt;= nums[i]; j--) &#123; dp[j] = Math.min(dp[j], dp[j - nums[i]]); &#125; &#125; return dp[sum] &lt; 10000000; &#125; k &gt; 2 12345678910111213141516171819public static boolean canPartitionKSubsets(int[] nums, int k) &#123; int sum = 0; for(int num:nums)sum += num; if(k &lt;= 0 || sum%k != 0)return false; int[] visited = new int[nums.length]; return canPartition(nums, visited, 0, k, 0, 0, sum/k); &#125;public static boolean canPartition(int[] nums, int[] visited, int start_index, int k, int cur_sum, int cur_num, int target)&#123; if(k==1)return true; if(cur_sum == target &amp;&amp; cur_num&gt;0)return canPartition(nums, visited, 0, k-1, 0, 0, target); for(int i = start_index; i&lt;nums.length; i++)&#123; if(visited[i] == 0)&#123; visited[i] = 1; if(canPartition(nums, visited, i+1, k, cur_sum + nums[i], cur_num++, target))return true; visited[i] = 0; &#125; &#125; return false; &#125;"},{"title":"AkkA_OSGi避坑指南","slug":"AkkA-OSGi避坑指南","date":"2017-11-20T15:47:41.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/11/20/AkkA-OSGi避坑指南/","text":"实验室项目需要，这段时间一直在搞AkkA框架在OSGi平台上的搭建，由于相关资料少之又少，可以说踩坑无数，于是有了写一篇避坑大全的想法。 依赖AkkA框架基于scala开发，所以在构建工程时，要注意AkkA同scala以及typesafe应该保持版本号一致 由pom构建 由SBT构建 版本不一致的话会报各种无法解析依赖的错误 配置文件AKKA框架会按照默认路径寻找配置文件application.conf，当然显示指定配置文件路径也可以，默认路径严格遵循以下路径： src\\main\\resources\\application.conf OSGi平台如何启动AkkA启动类Activator需继承ActorSystemActivator，config同start（startImp）函数作用相同，为Activator的启动函数，同时注意需要将ActorSystem注册到BundleContext上来 收发函数的调用 远程ActorRef的获取 多个配置文件共存上文提到AkkA会按照默认路径寻找配置文件，但假如OSGi平台当中存在多个配置文件，会导致当前bundle追寻到错误的配置文件，这个问题相当棘手。 比如bundleA存在配置文件application.confA，但是bundleA import 了BundleB，而bundleB拥有配置文件applicationB,那么BundleA最终调用的配置文件很有可能变成applicationB，而不是希望的applicationA，错误发生了。 而且很有可能报的是这样的错误： 后来发现，即使显示地指定bundleA配置文件application.conf的路径，这个错误依然存在，换句话说，只要OSGi平台当中存在多个配置文件，就会引发错误，所以可行的办法就是保证当前只有一个配置文件。"},{"title":"Two Pointer总结","slug":"Two-Pointer总结","date":"2017-11-19T06:32:47.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/11/19/Two-Pointer总结/","text":"前序Two Pointer应该说之前用到的还是很多的，像一次循环找到链表的中间元素，像快排等等，刚好这两天Leetcode刷到了Two Pointer这一块，借此机会做一个总结。在大多数适合于Two Pointer的场景下，恰当地使用Two pointer可以将复杂度维持在O(N)，特别是一些求解连续子序列相关的问题，Two pointer不失为一种很好地切入点。 Two pointer应用场景总结 合并两个sorted array到一个sorted array 一次循环找到链表的中间元素 判断一个链表是否存在环 找到链表中倒数第三个元素 求解连续子序列相关 接下来，我们将按照难度级别，对几个例子进行简单分析 Esay167. Two SumII - Input array is sortedGiven an array of integers that is already sorted in ascending order, find two numbers such that they add up to a specific target number. The function twoSum should return indices of the two numbers such that they add up to the target, where index1 must be less than index2. Please note that your returned answers (both index1 and index2) are not zero-based. You may assume that each input would have exactly one solution and you may not use the same element twice. Input: numbers={2, 7, 11, 15}, target=9Output: index1=1, index2=2 对于已经排好序的array，Two Pointer可以实现时间复杂度O(N)，空间复杂度为1，即两个pointer分别从两端向中间移动，其sun只有两种可能，和如果比target小，则左端指针右移，如果sum比target大，则右端指针左移，否则直接返回。如果不存在满则条件的解，则抛出异常。 MediumContinuousMaximumSubarray对于给定的array，求解不大于target的连续最大和子序列 对于这道求和题，除了Two Pointer的应用，还有一个技巧就是构造Cumulative sum array这样的一个递增序列，并且满足cumulative[end]-cumulative[start] &gt; target &amp;&amp; cumulative[end - 1] - cumulative[start] &lt;= target的条件，而start和end两个指针刚好定位了满足题设条件的连续子序列。 123456789101112131415161718192021222324public class ContinuousMaximumSubarray &#123; public static int[] continuousMaximumSubarray(int[] nums, int k) &#123; int[] sumArray = new int[nums.length + 1]; sumArray[0] = 0; int[] result = new int[2]; int sum = 0; for(int i = 0; i &lt; nums.length; i++) &#123; sum += nums[i]; sumArray[i + 1] = sum; &#125; int max = 0; int left = 0; int right = 0; while(left &lt; sumArray.length) &#123; while(right &lt; sumArray.length &amp;&amp; sumArray[right] - sumArray[left] &lt;= k) right++; if(max &lt; sumArray[right - 1] - sumArray[left]) &#123; max = sumArray[right - 1] - sumArray[left]; result[0] = left; result[1] = right - 2; &#125; left++; &#125; return result; &#125;&#125; ContinuousMinimumSubarray求解含有k个不同数字的连续最小和子序列 同上一道题相比，两道题如出一辙，只需对约束条件稍加修改即可。 123456789101112131415161718192021222324public class ContinuousMinimumSubarray &#123; public static int[] continuousMinimumSubarray(int[] nums, int k) &#123; int[] sumArray = new int[nums.length + 1]; sumArray[0] = 0; int[] result = new int[2]; int sum = 0; for(int i = 0; i &lt; nums.length; i++) &#123; sum += nums[i]; sumArray[i + 1] = sum; &#125; int right = 0; int left = 0; int min = Integer.MAX_VALUE; while(left &lt; sumArray.length) &#123; while(right &lt; sumArray.length &amp;&amp; right - left &lt; k) right++; if(right &lt; sumArray.length &amp;&amp; min &gt; sumArray[right] - sumArray[left]) &#123; min = sumArray[right] - sumArray[left]; result[0] = left; result[1] = right - 1; &#125; left++; &#125; return result; &#125;&#125; 209.Minimum Size Subarray SumGiven an array of n positive integers and a positive integer s, find the minimal length of a contiguous subarray of which the sum ≥ s. If there isn’t one, return 0 instead. For example, given the array [2,3,1,2,4,3] and s = 7,the subarray [4,3] has the minimal length under the problem constraint. 这道题如果稍微修改一下，即sum == s 而不是sum &gt;= s, 感觉可以直接应用map来解决，实际上属于拿空间换时间的方法，在此给出程序 12345678910111213141516public static int minSubArrayLen(int s, int[] nums) &#123; if(nums == null || nums.length == 0) return 0; Map&lt;Integer, Integer&gt; mapIndex = new HashMap&lt;Integer, Integer&gt;(); mapIndex.put(0, -1); int sumResult = 0; int min = Integer.MAX_VALUE; for(int i = 0; i &lt; nums.length; i++) &#123; sumResult += nums[i]; Integer pre = mapIndex.get(sumResult - s); if(pre != null) &#123; min = Math.min(min, i - pre); &#125; mapIndex.put(sumResult, i); &#125; return min; &#125; 而如果应用Two Pointer，则又回到了之前两道题的固定套路，区别仅仅是约束条件的改变，所谓万变不离其宗，最终left和right两个指针都可以为我们准确而方便地定位到满足题设的子序列。 注意cumulative[]和nums[]指针的差别和转换 12345678910111213141516171819public static int minSubArrayLen(int s, int[] nums) &#123; int[] sumArray = new int[nums.length + 1]; sumArray[0] = 0; int sum = 0; for(int i = 0; i &lt; nums.length; i++) &#123; sum += nums[i]; sumArray[i + 1] = sum; &#125; int min = Integer.MAX_VALUE; int left = 0; int right = 0; while(left &lt; sumArray.length) &#123; while(right &lt; sumArray.length &amp;&amp; sumArray[right] - sumArray[left] &lt; s) right++; if(right &lt; sumArray.length &amp;&amp; sumArray[right] - sumArray[left] &gt;= s &amp;&amp; min &gt; right - left) min = right - left; left++; &#125; return min &gt; 10000000 ? 0 : min; &#125; 567. Permutation in String 常规思路，构造 int[] cnt = new int[256]; int[] now = new int[256]; 这道题需要特别注意的应该是边界条件，即对于 right - left != s1.length() &amp;&amp; left &lt;= right 应该有now[s1.charAt(left)]–; 1234567891011121314151617public static boolean checkInclusion(String s1, String s2) &#123; int[] cnt = new int[256]; int[] now = new int[256]; for(int i = 0; i &lt; s1.length(); i++) cnt[s1.charAt(i)]++; int right = 0; int left = 0; while(left &lt; s2.length()) &#123; while(right &lt; s2.length() &amp;&amp; now[s2.charAt(right)] + 1 &lt;= cnt[s2.charAt(right)]) &#123; now[s2.charAt(right)] += 1; right++; &#125; if(right - left == s1.length()) return true; if(left &lt;= right) now[s2.charAt(left)]--; left++; &#125; return false;&#125;"},{"title":"递归  回溯  DFS","slug":"递归-回溯-DFS","date":"2017-11-06T07:22:17.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/11/06/递归-回溯-DFS/","text":"参考http://blog.csdn.net/ffmpeg4976/article/details/45007439 在程序设计中，有相当一类求一组解，或求全部解或求最优解的问题，例如读者熟悉的八皇后问题，不是根据某种特定的计算法则，而是利用试探和回溯的搜索技术求解。回溯法也是设计递归过程的一种重要方法，它的求解过程实质上是一个先序遍历一棵”状态树”的过程,只是这棵树不是遍历前预先建立的,而是隐含在遍历过程中。 《数据结构》(严蔚敏)怎么理解这段话呢？ 首先，某种问题的解我们很难去找规律计算出来，没有公式可循，只能列出所有可能的解，然后一个个检查每个解是否符合我们要找的条件，也就是通常说的遍历。而解空间很多是树型的，就是树的遍历。其次，树的先序遍历，也就是根是先被检查的，二叉树的先序遍历是根，左子树，右子树的顺序被输出。如果把树看做一种特殊的图的话，DFS就是先序遍历。所以，回溯和DFS是联系非常紧密的，可以认为回溯是DFS的一种应用场景。另外，DFS有个好处，它只存储深度，不存储广度。所以空间复杂度较小，而时间复杂度较大。 最后，某些解空间是非常大的，可以认为是一个非常庞大的树，此时完全遍历的时间复杂度是难以忍受的。此时可以在遍历的同时检查一些条件，当遍历某分支的时候，若发现条件不满足，则退回到根节点进入下一个分支的遍历。这就是“回溯”这个词的来源。而根据条件有选择的遍历，叫做剪枝或分枝定界。 Wiki上有一个很棒的回溯法的演示："},{"title":"Construct Binary Tree from Array","slug":"Construct-Binary-Tree-from-Array","date":"2017-11-06T07:16:41.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/11/06/Construct-Binary-Tree-from-Array/","text":"105. Construct Binary Tree from Preorder and Inorder Traversal 106. Construct Binary Tree from Inorder and Postorder Traversal 可以说是两道再经典不过的dfs题了,思路都很清晰，在这里记录一下吧123456789101112131415161718public TreeNode buildTree(int[] preorder, int[] inorder) &#123; return helper(0, 0, inorder.length - 1, preorder, inorder);&#125;public TreeNode helper(int preStart, int inStart, int inEnd, int[] preorder, int[] inorder) &#123; if (preStart &gt; preorder.length - 1 || inStart &gt; inEnd) &#123; return null; &#125; TreeNode root = new TreeNode(preorder[preStart]); int inIndex = 0; // Index of current root in inorder for (int i = inStart; i &lt;= inEnd; i++) &#123; if (inorder[i] == root.val) &#123; inIndex = i; &#125; &#125; root.left = helper(preStart + 1, inStart, inIndex - 1, preorder, inorder); root.right = helper(preStart + inIndex - inStart + 1, inIndex + 1, inEnd, preorder, inorder); return root;&#125; 123456789101112131415161718192021public TreeNode buildTreePostIn(int[] inorder, int[] postorder) &#123; if (inorder == null || postorder == null || inorder.length != postorder.length) return null; HashMap&lt;Integer, Integer&gt; hm = new HashMap&lt;Integer,Integer&gt;(); for (int i=0;i&lt;inorder.length;++i) hm.put(inorder[i], i); return buildTreePostIn(inorder, 0, inorder.length-1, postorder, 0, postorder.length-1,hm);&#125;private TreeNode buildTreePostIn(int[] inorder, int is, int ie, int[] postorder, int ps, int pe, HashMap&lt;Integer,Integer&gt; hm)&#123; if (ps&gt;pe || is&gt;ie) return null; TreeNode root = new TreeNode(postorder[pe]); int ri = hm.get(postorder[pe]); TreeNode leftchild = buildTreePostIn(inorder, is, ri-1, postorder, ps, ps+ri-is-1, hm); TreeNode rightchild = buildTreePostIn(inorder,ri+1, ie, postorder, ps+ri-is, pe-1, hm); root.left = leftchild; root.right = rightchild; return root;&#125;"},{"title":"动态规划问题带备忘自顶向下方法的典型应用","slug":"动态规划问题带备忘自顶向下方法的典型应用","date":"2017-11-05T06:29:22.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/11/05/动态规划问题带备忘自顶向下方法的典型应用/","text":"44. Wildcard Matching 10. Regular Expression Matching 两道题思路基本相同，所以我放在了一起来看，都可以归结到两个字符串求最长匹配子序列问题。我的算法是全部应用带备忘的自顶向下方法，跟Leetcode排名比较靠前的几个答案比较了一下，思路要更加清晰一些，并且由于该方法在某些情况下并不需要考察全部的子问题，所以实际运行时间可能会更少一些。 12345678910111213141516171819202122232425262728293031323334353637public static boolean isMatch(String s, String p) &#123; int[][] dp = new int[s.length() + 1][p.length() + 1]; int result = 0; result = help(s, p, dp, s.length(), p.length()); if(result == s.length()) return true; //(s.length() &gt; p.length() ? s.length(): p.length())) return true; else return false; &#125; private static int help(String s, String p, int[][] dp, int len1, int len2) &#123; if(dp[len1][len2] != 0) return dp[len1][len2]; if(len1 == 0 &amp;&amp; len2 == 0) return 0; else if(len1 == 0) &#123; for(int i = 0; i &lt; len2; i++) &#123; if(p.charAt(i) != '*') return -1; &#125; return 0; &#125; else if(len2 == 0) return -1; if(s.charAt(len1 - 1) == p.charAt(len2 - 1) || p.charAt(len2 - 1) == '?') &#123; int temp = help(s, p, dp, len1 - 1, len2 - 1); if(temp != -1) dp[len1][len2] = temp + 1; else return -1; &#125;else if(p.charAt(len2 - 1) == '*') &#123; int temp_1 = help(s, p, dp, len1 - 1, len2 - 1); if(temp_1 != -1) dp[len1][len2] = temp_1 + 1; else &#123; int temp_2 = help(s, p, dp, len1 - 1, len2); if(temp_2 != -1) dp[len1][len2] = temp_2 + 1; else &#123; int temp_3 = help(s, p, dp, len1, len2 - 1); dp[len1][len2] = temp_3; &#125; &#125; &#125;else &#123; return -1; &#125; return dp[len1][len2]; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public static boolean isMatch(String s, String p) &#123; int[][] dp = new int[s.length() + 1][p.length() + 1]; int result = 0; result = help(s, p, dp, s.length(), p.length()); if(result == s.length()) return true; else return false; &#125; private static int help(String s, String p, int[][] dp, int len1, int len2) &#123; if(dp[len1][len2] != 0) return dp[len1][len2]; if(len1 == 0 &amp;&amp; len2 == 0) return 0; else if(len1 == 0) &#123; if(len2 == 1) return -1; for(int i = 0; i &lt; len2 - 1; i ++) &#123; if(p.charAt(i) != '*') if(i + 1 &lt; len2 &amp;&amp; p.charAt(i + 1) != '*') return -1; else continue; else continue; &#125; if(p.charAt(len2 - 1) != '*') return -1; return 0; &#125; else if(len2 == 0) return -1; if(s.charAt(len1 - 1) == p.charAt(len2 - 1) || p.charAt(len2 - 1) == '.') &#123; int temp = help(s, p, dp, len1 - 1, len2 - 1); if(temp != -1) dp[len1][len2] = temp + 1; else return -1; &#125;else if(p.charAt(len2 - 1) == '*' &amp;&amp; ( p.charAt(len2 - 2) == s.charAt(len1 - 1) || p.charAt(len2 - 2) == '.')) &#123; int temp_1 = help(s, p, dp, len1 - 1, len2 - 1); if(temp_1 != -1) dp[len1][len2] = temp_1 + 1; else &#123; int temp_2 = help(s, p, dp, len1 - 1, len2); if(temp_2 != -1) dp[len1][len2] = temp_2 + 1; else &#123; int temp_3 = help(s, p, dp, len1, len2 - 2); dp[len1][len2] = temp_3; &#125; &#125; &#125;else if(p.charAt(len2 - 1) == '*' &amp;&amp; p.charAt(len2 - 2) != s.charAt(len1 - 1)) &#123; int temp = help(s, p, dp, len1, len2 - 2); dp[len1][len2] = temp; &#125; else &#123; return -1; &#125; return dp[len1][len2]; &#125;"},{"title":"Map在动态规划问题当中的应用","slug":"Map在动态规划问题当中的应用","date":"2017-11-05T06:27:59.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/11/05/Map在动态规划问题当中的应用/","text":"140. Word Break II 638. Shopping Offers 这两道题非常适合合在一起来看，通常动态规划问题适合用数组或者散列表来保存子问题的求解状态，但在某些情况下，比如子问题的状态是用列表或者字符串，不容易转化为数组，使用Map来保存子问题状态会更加便利，作为一种思路的拓展吧。 12345678910111213141516171819202122232425262728293031323334353637public class ShoppingOffers &#123; public static int shoppingOffers(List&lt;Integer&gt; price, List&lt;List&lt;Integer&gt;&gt; special, List&lt;Integer&gt; needs) &#123; Map&lt;List&lt;Integer&gt;, Integer&gt; dp = new HashMap&lt;&gt;(); List&lt;Integer&gt; allZero = new ArrayList&lt;&gt;(); for(int i=0;i&lt;needs.size();i++) &#123; allZero.add(0); &#125; dp.put(allZero, 0); return dfs(needs, price, special, dp); &#125; private static int dfs(List&lt;Integer&gt; needs, List&lt;Integer&gt; price, List&lt;List&lt;Integer&gt;&gt; special, Map&lt;List&lt;Integer&gt;, Integer&gt; dp) &#123; if(dp.containsKey(needs)) return dp.get(needs); int res = Integer.MAX_VALUE; for(List&lt;Integer&gt; s : special) &#123; List&lt;Integer&gt; needsCopy = new ArrayList&lt;&gt;(needs); boolean valid = true; for(int i=0;i&lt;needs.size();i++) &#123; needsCopy.set(i, needsCopy.get(i) - s.get(i)); if(needsCopy.get(i) &lt; 0) &#123; valid = false; break; &#125; &#125; if(valid) &#123; res = Math.min(res, s.get(needs.size()) + dfs(needsCopy, price, special, dp)); &#125; &#125; int noSpecial = 0; for(int i=0;i&lt;needs.size();i++) &#123; noSpecial += needs.get(i) * price.get(i); &#125; res = Math.min(res, noSpecial); dp.put(needs, res); return res; &#125;&#125; 12345678910111213141516171819202122232425262728public static List&lt;String&gt; wordBreak(String s, List&lt;String&gt; wordDict) &#123; Map&lt;String, List&lt;String&gt;&gt; map = new HashMap&lt;String, List&lt;String&gt;&gt;(); return dfs(s, wordDict, map); &#125; private static List&lt;String&gt; dfs(String s, List&lt;String&gt; wordDict, Map&lt;String, List&lt;String&gt;&gt; map) &#123; if(map.containsKey(s)) &#123; return map.get(s); &#125; List&lt;String&gt; res = new ArrayList&lt;String&gt;(); if(s.length() == 0) &#123; res.add(\"\"); return res; &#125; for(String word : wordDict) &#123; if(s.startsWith(word)) &#123; List&lt;String&gt; subList = dfs(s.substring(word.length()), wordDict, map); for(String sub : subList) res.add(word + (sub.isEmpty() ? \"\" : \" \") + sub); &#125; &#125; map.put(s, res); return res; &#125; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(\"cat\"); list.add(\"cats\"); list.add(\"and\"); list.add(\"sand\");list.add(\"dog\");list.add(\"t\"); System.out.println(WordBreak.wordBreak(\"catsanddog\", list).size()); &#125;"},{"title":"InterleavingString","slug":"InterleabingString","date":"2017-11-02T02:19:53.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/11/02/InterleabingString/","text":"动态规划问题到目前为止已经刷了差不多40余题，借几道题稍微做一个总结。 97. Interleaving String 典型的动态规划问题。首先自然想到构造维度分别为s1.length()+1和s2.length()+1的boolean类型二维数组matrix 另外，组成字符串s3的char要么来自s1，要么来自s2，因此，顺次将s1同s2和s3进行比较即可 1234567891011当row == 0for 1 to s2.length() &lt;--- colmatrix[0][col] = matrix[0][col-1] &amp;&amp; (s2.charAt(col-1) == s3.charAt(col-1))当col == 0for 1 to s1.length() &lt;--- rowmatrix[0][col] = matrix[row-1][0] &amp;&amp; (s1.charAt(row-1) == s3.charAt(row-1))for 1 to s1.length() &lt;---rowfor 1 to s2.length() &lt;---colmatrix[row][col] = (matrix[row-1][col] &amp;&amp; s1.charAt(row-1) == s3.charAt(row+col-1) || (matrix[row][col] &amp;&amp; s2.charAt(col-1) == s3.charAt(row + col -1))return matrix[s1.length()][s2.length()] 123456789101112131415161718192021222324252627 public boolean isInterleave(String s1, String s2, String s3) &#123; if ((s1.length()+s2.length())!=s3.length()) return false; boolean[][] matrix = new boolean[s2.length()+1][s1.length()+1]; matrix[0][0] = true; for (int i = 1; i &lt; matrix[0].length; i++)&#123; matrix[0][i] = matrix[0][i-1]&amp;&amp;(s1.charAt(i-1)==s3.charAt(i-1)); &#125; for (int i = 1; i &lt; matrix.length; i++)&#123; matrix[i][0] = matrix[i-1][0]&amp;&amp;(s2.charAt(i-1)==s3.charAt(i-1)); &#125; for (int i = 1; i &lt; matrix.length; i++)&#123; for (int j = 1; j &lt; matrix[0].length; j++)&#123; matrix[i][j] = (matrix[i-1][j]&amp;&amp;(s2.charAt(i-1)==s3.charAt(i+j-1))) || (matrix[i][j-1]&amp;&amp;(s1.charAt(j-1)==s3.charAt(i+j-1))); &#125; &#125; return matrix[s2.length()][s1.length()];&#125; 其中，时间复杂度为O(s1.length() * s2.length())"},{"title":"MinimumASCIIDeleteSum","slug":"MinimumASCIIDeleteSum","date":"2017-11-02T02:19:08.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/11/02/MinimumASCIIDeleteSum/","text":"712. Minimum ASCII Delete Sum for Two Strings 其实动态规划问题，个人感觉好的算法，首先是明确每个阶段的状态去表征什么，再次才是寻找状态转移方程。 总结一下动态规划问题的策略步骤： 子问题的划分。 按照一定的顺序把整个问题划分为若干个规模相等的子问题。 子问题状态的确定。根据问题需求和子问题的各个属性确定子问题的”状态“，同时需要满足无后效性。 推导状态转移方程。 状态转移指的就是根据上一个状态（或者叫上一个子问题的解）来获取当前子问题解的过程。 如果要进行具体的计算，那么就需要写出具体的算式。这一步也是最需要时间的，传说中最考验功力的一关 边界条件和初始值的确定。由于动态规划是根据之前子问题的解来推导当前子问题的解，所以最初状态的值必须确定。边界条件是用来描述结束状态的，如果当前状态完全到达边界，便视为已经到达了最终状态。 这道题，同样，当我们构造出一个二维状态数组时，这个数组应该表示什么？我的想法是每个状态去表征s1前row的子字符串和s2前col字符串删除的最小ASCII码。 这道题我用了递归，感觉思路会更明确一些，当然两层循环嵌套也可以，两种方法复杂度相当。 在这里，总结一下动态规划的两种等价实现方法: 带备忘的自顶向下法。此方法仍按照自然的递归形式编写过程，但过程会保存每一个子问题的解（通常保存在数组或散列表当中）。当需要一个子问题的解时，过程首先检查过程是否已保存过此解。如果是，则直接返回保存的结果，否则，按通常方式计算这个子问题。我们称这个递归过程是带备忘的。因为它已经记住了之前已经计算的结果 第二种方法称为自底向上法。这种问题一般需要恰当定义子问题“规模”的概念，使得任何子问题的求解都只依赖于“更小子问题”的求解。因而我们可以将子问题按规模排序，按由小至大的顺序进行求解。当求解某个子问题时，它所依赖的那些更小的子问题都已经求解完毕，结果已经保存。每个子问题只需要求解一次，当我们求解它（也是第一次遇到它）时，它的所有前提子问题都已经求解完成。 两种方法得到的算法具有相同的渐进运行时间，仅有的差异是在某些特殊情况下，自顶向下的方法并为真正递归所有可能的子问题。另外，由于没有频繁地递归函数调用的开销，自底向上方法的时间复杂性函数通常具有更小的系数。 直接上代码 123456789101112131415161718192021222324252627282930313233343536public int minimumDeleteSum(String s1, String s2) &#123; int[][] dp = new int[s1.length() + 1][s2.length() + 1]; return findMinSum(s1,s2,s1.length(),s2.length(),dp);&#125;public int findMinSum(String s1,String s2,int len1,int len2,int[][] dp)&#123; if(dp[len1][len2] != 0)&#123; return dp[len1][len2]; &#125; if(len1==0 &amp;&amp; len2==0)&#123; dp[len1][len2]=0; return 0; &#125;else if(len1 == 0)&#123; int t = findMinSum(s1, s2, 0, len2 - 1, dp); dp[0][len2] = t + (int)s2.charAt(len2 - 1); return dp[0][len2]; &#125;else if(len2 == 0)&#123; int t = findMinSum(s1,s2,len1-1,0,dp); dp[len1][0] = t + (int)s1.charAt(len1 - 1); return dp[len1][0]; &#125; if(s1.charAt(len1 - 1) == s2.charAt(len2 - 1))&#123; int temp = findMinSum(s1,s2,len1 - 1,len2 - 1,dp); dp[len1][len2]=temp; &#125;else&#123; int temp1 = findMinSum(s1, s2, len1, len2 - 1, dp); int temp2 = findMinSum(s1, s2, len1 - 1, len2, dp); dp[len1][len2] = Math.min(temp1 + (int)s2.charAt(len2 - 1),temp2 + (int)s1.charAt(len1 - 1)); &#125; return dp[len1][len2];&#125;"},{"title":"CountRepetition","slug":"CountRepetition","date":"2017-11-02T02:15:40.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/11/02/CountRepetition/","text":"466. Count The Repetitions 首先这道题我非常喜欢，为什么呢，因为我没做出来，最后看一种复杂度非常低的答案时，发现思路完全一致，但是自己又差了一点点，每次差的这一点，反映出的依然是自己在算法方面的巨大不足。 public class Solution { public int getMaxRepetitions(String s1, int n1, String s2, int n2) { int count = 0; int k = 0; int index = 0; int repTime = 0; int[] rests = new int[200]; int[] reps = new int[200]; while(k == count) { count++; for(int i = 0; i &lt; s1.length(); i++) { if(s1.charAt(i) == s2.charAt(index)) { index++; if(index == s2.length()) { repTime++; index = 0; } } } if(count &gt; n1) return repTime / n2; for(k = 0; k &lt;count; k++) { if(index == rests[k]) break; } reps[count] = repTime; rests[count] = index; } int interval = count - k; int repeatCount = (n1 - k) / interval; int repeatTimes = repeatCount * (reps[count] - reps[k]); int remainTimes = reps[(n1 - k) % interval + k]; return (repeatTimes + remainTimes) / n2; // int repeatCount = n1 / count; // int repeatTimes = repeatCount * reps[count]; // int remainTimes = reps[n1 % count]; // return (repeatTimes + remainTimes) / n2; } } 首先这道题，S1是由n个s1组合而成，S2是由m个s2组合而成，因此考虑S1最多可以构成多少个S2时，显然不需要考虑全部的S1和S2，而只需要考虑s1和s2。另外需要想到， 一个s1和多个s1所能构成的s2可能并不是简单的倍数关系 当一个s1遍历一遍时，当s2的index相同时，可以认为构成了循环"},{"title":"Strange priter","slug":"Strange-priter","date":"2017-10-19T10:26:55.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/10/19/Strange-priter/","text":"664. Strange Printer 这道题的难度感觉是很大的，目前想到的方法是 &lt;O(n^3),（其中n小于或等于字符串长度）是否存在更低时间复杂度，例如能否将某个维度降到logn级别还在进一步思考当中。直接看代码 class Solution { public int strangePrinter(String s) { if (s.length() == 0) return 0; char[] sa = s.toCharArray(); int n = 1; for (int i = 1; i < sa.length; ++i) { if (sa[i] == sa[n - 1]) continue; sa[n++] = sa[i]; } //去除数组当中的相邻且重复元素，降低数组长度，起到压缩数组的作用 int[][] dp = new int[n][n]; for (int j = 0; j < n; ++j) { dp[j][j] = 1; for (int i = j - 1; i >= 0; --i) { if (sa[i] == sa[j]) { dp[i][j] = dp[i][j - 1]; continue; } dp[i][j] = dp[i][j - 1] + 1; for (int k = i + 1; k < j; ++k) { if (sa[k] == sa[j]) { if (dp[i][k - 1] + dp[k][j] < dp[i][j]) { dp[i][j] = dp[i][j - 1]; break; //算法当中不可能存在可以两次松弛的情况，因此可以直接break，减少循环次数 } } } } } return dp[0][n - 1]; } }"},{"title":"Matchstickes to Square","slug":"Matchstickes-to-Square","date":"2017-09-15T09:16:10.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/09/15/Matchstickes-to-Square/","text":"473. Matchsticks to Square"},{"title":"Remove Invalid Parentheses","slug":"Remove-Invalid-Parentheses","date":"2017-09-13T09:48:01.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/09/13/Remove-Invalid-Parentheses/","text":"301. Remove Invalid Parentheses考虑使用DFS，通过递归顺序遍历字符串，其中当遍历到’(‘和’)’时，均存在将其加入字符串和抛弃掉两种情况 class Solution { public List removeInvalidParentheses(String s) { int rmL = 0, rmR = 0; for (int i = 0; i < s.length(); i++) { if (s.charAt(i) == '(') { rmL++; } else if (s.charAt(i) == ')') { if (rmL != 0) { rmL--; } else { rmR++; } } } Set res = new HashSet(); dfs(s, 0, res, new StringBuilder(), rmL, rmR, 0); return new ArrayList(res); } public void dfs(String s, int i, Set res, StringBuilder sb, int rmL, int rmR, int open) { if (rmL < 0 || rmR < 0 || open < 0) { return; } if (i == s.length()) { if (rmL == 0 && rmR == 0 && open == 0) { res.add(sb.toString()); } return; } char c = s.charAt(i); int len = sb.length(); if (c == '(') { dfs(s, i + 1, res, sb, rmL - 1, rmR, open); // not use ( dfs(s, i + 1, res, sb.append(c), rmL, rmR, open + 1); // use ( } else if (c == ')') { dfs(s, i + 1, res, sb, rmL, rmR - 1, open); // not use ) dfs(s, i + 1, res, sb.append(c), rmL, rmR, open - 1); // use ) } else { dfs(s, i + 1, res, sb.append(c), rmL, rmR, open); } sb.setLength(len); } }"},{"title":"Binary Tree Maximum Path Sum","slug":"Binary-Tree-Maximum-Path-Sum","date":"2017-09-13T08:09:36.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/09/13/Binary-Tree-Maximum-Path-Sum/","text":"124. Binary Tree Maximum Path Sum这道题需要注意的地方是二叉树节点值可能为负数，因此在确定是否将左右子树最大值引入时，应该同0进行比较，同时应在每个节点处判断是否以该节点作为Sequence的根节点。 class Solution { private int sum = Integer.MIN_VALUE; public int maxPathSum(TreeNode root) { if(root == null) return 0; maxPath(root); return sum; } public int maxPath(TreeNode root) { if(root == null) return 0; int sumLeft = Math.max(0, maxPath(root.left)); int sumRight = Math.max(0, maxPath(root.right)); sum = Math.max(sum,sumLeft + sumRight + root.val); return Math.max(sumLeft,sumRight) + root.val; } }"},{"title":"中序遍历的应用","slug":"中序遍历的应用","date":"2017-09-13T07:41:51.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/09/13/中序遍历的应用/","text":"对于二叉树，当涉及到将二叉树转化为有序数组的问题时，应该首先考虑中序遍历和后序遍历。如题：使用中序遍历："},{"title":"最小高度树","slug":"最小高度树","date":"2017-09-07T02:21:38.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/09/07/最小高度树/","text":"310. Minimum Height TreesFor a undirected graph with tree characteristics, we can choose any node as the root. The result graph is then a rooted tree. Among all possible rooted trees, those with minimum height are called minimum height trees (MHTs). Given such a graph, write a function to find all the MHTs and return a list of their root labels.Format The graph contains n nodes which are labeled from 0 to n - 1. You will be given the number n and a list of undirected edges (each edge is a pair of labels). You can assume that no duplicate edges will appear in edges. Since all edges are undirected, [0, 1] is the same as [1, 0] and thus will not appear together in edges. 在已知树形结构求树根的问题，优先解决方案应该是BFS，从叶子节点逐层遍历，直到找到满足要求的树根 class Solution { public List findMinHeightTrees(int n, int[][] edges) { List[] adj = (ArrayList[]) new ArrayList[n]; for(int i = 0; i 2) { n -= result.size(); List newResult = new ArrayList(); for(int vertex : result) { int parent = adj[vertex].get(0); adj[parent].remove((Integer)vertex); if(adj[parent].size() == 1) newResult.add(parent); } result = newResult; } return result; } }"},{"title":"opendaylightplugin学习笔记（一）——StatisticsManager","slug":"opendaylightplugin学习笔记（一）——StatisticsManager-1","date":"2017-07-27T16:00:36.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/07/28/opendaylightplugin学习笔记（一）——StatisticsManager-1/","text":"@(Opendaylight)[openflowplugin|statistics-manager|beryllium] StatNodeRegistrationImpl StaNodeRegistrationImpl在铍版本似乎实现的是之前版本Inventory-Manager中NodeChangeCommit获取节点和端口信息的功能，也就说在铍版本，节点、端口信息获取和存储功能似乎从Inventory-mananger转移到了statistics-manager。有待于进一步证实。所在包 org.opendaylight.openflowplugin.applications.statistics.manager实现接口org.opendaylight.openflowplugin.applications.statistics.manager.StatNodeRegistrationorg.opendaylight.controller.md.sal.common.api.clustering.EntityOwnershipListenerRegistration祖父接口org.opendaylight.yang.gen.v1.urn.opendaylight.inventory.rev130819.OpendaylightInventoryListenerjava.lang.AutoCloseableorg.opendaylight.yangtools.yang.binding.NotificationListenerjava.util.EventListener 1public interface EventListener 所有的事件侦听器必须拓展的标记接口 OpendaylightInventoryListener注册OpendaylightInvenrtoyListener监听器，当ODL控制器与openflow交换机建立连接时，或者断开连接，openflow交换机端口发生Down事件、Up事件时，会分别触发以下函数 1234567891011121314151617181920void onNodeConnectorRemoved(NodeConnectorRemoved notification);/*交换机端口Down事件一个NodeConnector被移除则发起通知，但并不会更改节点树。所描述的是一个节点被移除但基于某种原因节点树并没有被修改*/void onNodeRemoved(NodeRemoved notification);/*交换机下线事件一个Node被移除则发起通知，但并不会更改节点树。所描述的是一个节点被移除但基于某种原因节点树并没有被修改*/void onNodeUpdated(NodeUpdated notification);/*交换机上线事件一个Node被修改则发起通知，但并不会更改节点树。所描述的是一个节点被修改但基于某种原因节点树并没有被修改*/void onNodeConnectorUpdated(NodeConnectorUpdated notification);/*交换机端口Up事件一个NodeConnector被修改则发起通知，但并不会更改节点树。所描述的是一个节点被修改但基于某种原因节点树并没有被修改*/ StatNotifyCommitPort（端口信息）所在包org.opendaylight.openflowplugin.applications.statistics.manager.impl 一个NotifyListener针对PortStatistics，所有期望或者注册的的PortStatistics将被提交给Datastore或者Operational StatNotifyCommitTable（流表信息） 同inventory-manager内的NodeTableFeatureCommit 功能是一致的 所在包org.opendaylight.openflowplugin.applications.statistics.manager.impl继承类StatAbstractNotifyCommit&lt;· N extends NotificationListener&gt; StatAbstractNotifyCommit&lt;·N extends NotificationListener&gt;123public StatAbstractListenCommit(final StatisticsManager manager, final DataBroker db,final NotificationProviderService nps, final Class&lt;T&gt; clazz, final StatNodeRegistration nodeRegistrationManager) Class is abstract implementation for all no Configuration/DataStore DataObjects and represent common functionality for all DataObject Statistics Commiters. Class defines contract between DataObject and relevant Statistics NotificationListener. 继承祖父类StatNotifyCommiter&lt;·N&gt; 实现接口OpendaylightFlowTableStatisticsListener 12345678910public interface OpendaylightFlowTableStatisticsListener extends NotificationListener&#123; /** * Receive flow table statistics update * */ void onFlowTableStatisticsUpdate(FlowTableStatisticsUpdate notification);&#125; Class is a NotifyListener for TableStatistics All expected (registered) tableStatistics will be builded and commit to Operational/DataStore StatListenCommitMeter（Meter）所在包org.opendaylight.openflowplugin.applications.statistics.manager.impl 1public StatListenCommitMeter(final StatisticsManager manager, final DataBroker db, final NotificationProviderService nps, final StatNodeRegistration nrm) StatListenCommitMeter Class is a NotifyListener for MeterStatistics and DataChangeListener for Config/DataStore for Meter node. All expected (registered) MeterStatistics will be builded and commit to Operational/DataStore. DataChangeEven should call create/delete Meter in Operational/DS StatListenCommitGroup（Group）所在包org.opendaylight.openflowplugin.applications.statistics.manager.impl 1public StatListenCommitGroup(final StatisticsManager manager, final DataBroker db, final NotificationProviderService nps,final StatNodeRegistration nrm) Class is a NotifyListener for GroupStatistics and DataChangeListener for Config/DataStore for Group node.All expected (registered) GroupStatistics will be builded and commit to Operational/DataStore. DataChangeEven should call create/delete Group in Operational/DS Statistics.Manger It represent a central point for whole module. Implementation DataStore的数据存储包含两种形式，分别为Config/DS和Operational/DS,config持有由应用所写的数据，oprational反映了设备实际的状态StatisticsManager registers all Operation/DS {@link StatNotifyCommiter} and Config/DS {@link StatListeningCommiter}, as well as {@link StatPermCollector} for statistic collecting and {@link StatRpcMsgManager} as Device RPCs provider. In next, StatisticsManager provides all DS contact Transaction services.即完成所有注册之后，提供所有的DataStore数据交互业务的服务123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140/** * 整个statistics-manager的入口函数 * * @param notifService * @param rpcRegistry */ void start(final NotificationProviderService notifService, final RpcConsumerRegistry rpcRegistry); /** * Method provides read/write DataStore functionality cross applyOperation * defined in &#123;@link StatDataStoreOperation&#125; * * @param inventoryOper - operation for DataStore */ void enqueue(final StatDataStoreOperation inventoryOper); /** * Method wraps &#123;@link StatisticsManager#isProvidedFlowNodeActive(InstanceIdentifier)&#125; method * to provide parallel statCollection process for Set of Nodes. So it has to * identify correct Node Set by NodeIdentifier * * @param nodeIdent */ boolean isProvidedFlowNodeActive(InstanceIdentifier&lt;Node&gt; nodeIdent); /** * Method wraps &#123;@link StatPermCollector&#125;.collectNextStatistics to provide * parallel statCollection process for Set of Nodes. So it has to * identify correct Node Set by NodeIdentifier. * * @param nodeIdent */ void collectNextStatistics(InstanceIdentifier&lt;Node&gt; nodeIdent, TransactionId xid); /** * Method wraps &#123;@link StatPermCollector&#125;.connectedNodeRegistration to provide * parallel statCollection process for Set of Nodes. So it has to * connect node to new or not full Node statCollector Set. * * @param nodeIdent * @param statTypes * @param nrOfSwitchTables */ void connectedNodeRegistration(InstanceIdentifier&lt;Node&gt; nodeIdent, List&lt;StatCapabTypes&gt; statTypes, Short nrOfSwitchTables); /** * Method wraps &#123;@link StatPermCollector&#125;.disconnectedNodeUnregistration to provide * parallel statCollection process for Set of Nodes. So it has to identify * correct collector for disconnect node. * * @param nodeIdent */ void disconnectedNodeUnregistration(InstanceIdentifier&lt;Node&gt; nodeIdent); /** * Method wraps &#123;@link StatPermCollector&#125;.registerAdditionalNodeFeature to provide * possibility to register additional Node Feature &#123;@link StatCapabTypes&#125; for * statistics collecting. * * @param nodeIdent * @param statCapab */ void registerAdditionalNodeFeature(InstanceIdentifier&lt;Node&gt; nodeIdent, StatCapabTypes statCapab); /** * Method wraps &#123;@link StatPermCollector&#125;.unregisterNodeStats to provide * possibility to unregister Node stats type &#123;@link StatCapabTypes&#125; from * statistics collecting. * * @param nodeIdent * @param statCapab */ void unregisterNodeStats(InstanceIdentifier&lt;Node&gt; nodeIdent, StatCapabTypes statCapab); /** * Method provides access to Device RPC methods by wrapped * internal method. In next &#123;@link StatRpcMsgManager&#125; is registered all * Multipart device msg response and joining all to be able run all * collected statistics in one time (easy identification Data for delete) * * @return &#123;@link StatRpcMsgManager&#125; */ StatRpcMsgManager getRpcMsgManager(); /** * Define Method : &#123;@link org.opendaylight.yang.gen.v1.urn.opendaylight.flow.inventory.rev130819.FlowCapableNode&#125; * Operational/DS data change listener -&amp;gt; impl. target -&amp;gt; register FlowCapableNode to Statistic Collecting process * @return &#123;@link StatNodeRegistration&#125; */ StatNodeRegistration getNodeRegistrator(); /** * Define Method : Flow Config/DS data change listener -&amp;gt; impl. target -&amp;gt; * -&amp;gt; make pair between Config/DS FlowId and Device Flow response Hash * @return */ StatListeningCommiter&lt;Flow, OpendaylightFlowStatisticsListener&gt; getFlowListenComit(); /** * Define Method : Meter Config/DS data change listener and Operation/DS notify commit * functionality * @return */ StatListeningCommiter&lt;Meter, OpendaylightMeterStatisticsListener&gt; getMeterListenCommit(); /** * Define Method : Group Config/DS data change listener and Operation/DS notify commit * functionality * @return */ StatListeningCommiter&lt;Group, OpendaylightGroupStatisticsListener&gt; getGroupListenCommit(); /** * Define Method : Queue Config/DS change listener and Operation/DS notify commit functionality * @return */ StatListeningCommiter&lt;Queue, OpendaylightQueueStatisticsListener&gt; getQueueNotifyCommit(); /** * Define Method : Table Operation/DS notify commit functionality * @return */ StatNotifyCommiter&lt;OpendaylightFlowTableStatisticsListener&gt; getTableNotifCommit(); /** * Define Method : Port Operation/DS notify commit functionality * @return */ StatNotifyCommiter&lt;OpendaylightPortStatisticsListener&gt; getPortNotifyCommit(); StatisticsManagerConfig getConfiguration(); /** * A unique UUID is generated with each node added by the statistics manager implementation in order to uniquely * identify a session. * @param nodeInstanceIdentifier */ UUID getGeneratedUUIDForNode(InstanceIdentifier&lt;Node&gt; nodeInstanceIdentifier);"},{"title":"opendaylightplugin学习笔记（二）——TopologyManager","slug":"opendaylightplugin学习笔记（二）——TopologyManager-1","date":"2017-07-27T15:57:43.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/07/27/opendaylightplugin学习笔记（二）——TopologyManager-1/","text":"topology-manager模块是作为openflowplugin的应用层程序（Applications），负责处理operational数据库下network-topology:network-topology数据节点（datastore数据库）的增删改查，例如ODL控制器发现添加一台主机host、新加主机与交换机的link链接等。显示拓扑的前端需要从该数据节点上获取主机或者交换机节点数据才能绘制网络拓扑图，构成拓扑图来源有两方面，一方面是通过LLDP发现的switch设备以及相关link连接，另一外面是通过L2switch的hosttracker模块发现的下挂在switch上的host主机以及相关连接。"},{"title":"Apriori","slug":"Apriori","date":"2017-07-16T08:18:55.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/07/16/Apriori/","text":""},{"title":"netty之ChannelPipeline和ChannelHandler","slug":"netty之ChannelPipeline和ChannelHandler","date":"2017-07-15T09:43:09.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/07/15/netty之ChannelPipeline和ChannelHandler/","text":"Netty的ChannelPipeline和ChannelHandler机制类似于Servlet和Filter过滤器，这类拦截器实际上是职责连模式的一种变形（Netty的三层架构分别为通信业务层，职责链，上层业务），主要是方便事件的拦截和用户业务逻辑的定制。众所周知，Servlet Filter是JAVA Web应用程序级的java代码组件，它能够以声明的方式插入到HTTP请求响应的处理过程中，用于拦截请求和响应，以便能够查看、提取或以某种方式操作正在客户端和服务器之间交换的数据。拦截器封装了业务定制逻辑，能够实现对Web应用程序的预处理和事后处理。 过滤器提供了一种面向对象的模块化机制，用来将公共任务封装到可插入的组件中。这些组件通过Web部署配置文件(web.xml)进行声明，可以方便地添加或删除过滤器，无需改动任何应用程序代码或JSP页面，由Servlet进行动态调用。通过在请求、响应链中使用过滤器，可以对应用程序的Servlet或JSP页面提供的核心处理进行补充，而不破坏Servlet或JSP页面的功能。由于是纯Java实现，所以Servlet过滤器具有跨平台的可重用性，使得他们很容易被部署到任何符合Servlet规范的JEE环境中。 同样的，Netty将数据管道封装为一个ChannelPipeline，消息在ChannelPipeline中流动和传递，ChannelPipeline维护一个IO事件拦截器ChannelHandler链表并可实现迭代，通过新增和删除ChannelHandler来实现不同的业务逻辑定制。"},{"title":"小问题","slug":"小问题","date":"2017-07-11T02:28:37.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/07/11/小问题/","text":"今天吃饭的时候，问了自己一个问题，java反射到底是个啥，java反射可以实现啥？自己稍微总结一下： java反射是在程序运行时，拿到一个类可以得到类的全部属性和方法，拿到一个对象，可以调用对象的全部属性和方法。 java反射的作用： 判断一个实例对象是否属于某个类 构造类的实例化对象 获取类的全部方法和属性 调用对象的全部方法和属性 动态代理"},{"title":"并发锁与条件变量","slug":"并发锁与条件变量","date":"2017-07-09T05:44:44.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/07/09/并发锁与条件变量/","text":"《Java 并发编程实践》一书给出了使用 ReentrantLock 的最佳时机： 当你需要以下高级特性时，才应该使用：可定时的、可轮询的与可中断的锁获取操作，公平队列，或者非块结构的锁。否则，请使用 synchronized 互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因而这种同步又称为阻塞同步，它属于一种悲观的并发策略，即线程获得的是独占锁。独占锁意味着其他线程只能依靠阻塞来等待线程释放锁。而在 CPU 转换线程阻塞时会引起线程上下文切换，当有很多线程竞争锁的时候，会引起 CPU 频繁的上下文切换导致效率很低。synchronized 采用的便是这种并发策略。随着指令集的发展，我们有了另一种选择：基于冲突检测的乐观并发策略，通俗地讲就是先进性操作，如果没有其他线程争用共享数据，那操作就成功了，如果共享数据被争用，产生了冲突，那就再进行其他的补偿措施（最常见的补偿措施就是不断地重拾，直到试成功为止），这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步被称为非阻塞同步。ReetrantLock 采用的便是这种并发策略。 在乐观的并发策略中，需要操作和冲突检测这两个步骤具备原子性，它靠硬件指令来保证，这里用的是 CAS 操作（Compare and Swap）。JDK1.5 之后，Java 程序才可以使用CAS操作。我们可以进一步研究 ReentrantLock 的源代码，会发现其中比较重要的获得锁的一个方法是 compareAndSetState，这里其实就是调用的 CPU 提供的特殊指令。现代的 CPU 提供了指令，可以自动更新共享数据，而且能够检测到其他线程的干扰，而 compareAndSet() 就用这些代替了锁定。这个算法称作非阻塞算法，意思是一个线程的失败或者挂起不应该影响其他线程的失败或挂起。 Java 5 中引入了注入 AutomicInteger、AutomicLong、AutomicReference 等特殊的原子性变量类，它们提供的如：compareAndSet()、incrementAndSet()和getAndIncrement()等方法都使用了 CAS 操作。因此，它们都是由硬件指令来保证的原子方法。 性能比较 基本语法上，ReentrantLock 与 synchronized 很相似，它们都具备一样的线程重入特性，只是代码写法上有点区别而已，一个表现为 API 层面的互斥锁（Lock），一个表现为原生语法层面的互斥锁（synchronized）。ReentrantLock 相对 synchronized 而言还是增加了一些高级功能，主要有以下三项： 等待可中断：当持有锁的线程长期不释放锁时，正在等待的线程可以选择放弃等待，改为处理其他事情，它对处理执行时间非常上的同步块很有帮助。而在等待由 synchronized 产生的互斥锁时，会一直阻塞，是不能被中断的。 可实现公平锁：多个线程在等待同一个锁时，必须按照申请锁的时间顺序排队等待，而非公平锁则不保证这点，在锁释放时，任何一个等待锁的线程都有机会获得锁。synchronized 中的锁时非公平锁，ReentrantLock 默认情况下也是非公平锁，但可以通过构造方法 ReentrantLock（ture）来要求使用公平锁。 锁可以绑定多个条件：ReentrantLock 对象可以同时绑定多个 Condition 对象（名曰：条件变量或条件队列），而在 synchronized 中，锁对象的 wait()和 notify()或 notifyAll()方法可以实现一个隐含条件，但如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而 ReentrantLock 则无需这么做，只需要多次调用 newCondition()方法即可。而且我们还可以通过绑定 Condition 对象来判断当前线程通知的是哪些线程（即与 Condition 对象绑定在一起的其他线程）。 可中断锁 ReetrantLock 有两种锁：忽略中断锁和响应中断锁。忽略中断锁与 synchronized 实现的互斥锁一样，不能响应中断，而响应中断锁可以响应中断。 如果某一线程 A 正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程 B 不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，如果此时 ReetrantLock 提供的是忽略中断锁，则它不会去理会该中断，而是让线程B继续等待，而如果此时 ReetrantLock 提供的是响应中断锁，那么它便会处理中断，让线程 B 放弃等待，转而去处理其他事情。"},{"title":"匈牙利算法","slug":"匈牙利算法","date":"2017-07-06T02:41:37.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/07/06/匈牙利算法/","text":"二分图的最大匹配和完美匹配本质上还是最大网络流问题。基于深度优先遍历实现 public class Edmonds { private boolean[] used; private int[] girl; private int[][] path; private boolean[][] another; // private Queue[] queue ; @SuppressWarnings(“unchecked”)public Edmonds(int Num){ // queue = (Queue[]) new Queue[Num]; another = new boolean[Num][Num]; used = new boolean[Num]; Arrays.fill(used, false); girl = new int[Num]; Arrays.fill(girl, -1); path = new int[Num][Num]; for(int i = 0;i &lt; Num;i++){ Arrays.fill(path[i], 0); Arrays.fill(another[i], false); } } public Edmonds(In in){ this(in.readInt()); for(int i = 0 ; i &lt; used.length; i++){ for(int j = 0; j &lt; used.length; j++){ path[i][j] = in.readInt(); } } } public boolean find(int x){ for(int j = 0;j &lt; used.length;j++){ if(path[x][j] == 1 &amp;&amp; !another[x][j]){ if(!used[j]){ used[j] = true; girl[j] = x; another[x][j] = true; return true; } else{ if(find(girl[j])) return true; } } } return false; } public static void main(String[] args){ In in = new In(args[0]); int num = 0; Edmonds edmonds = new Edmonds(in); for(int i = 0;i &lt; edmonds.used.length;i++){ if(edmonds.find(i)) num++; } System.out.println(“The perfect matching is : “ + num); }"},{"title":"最大网络流(Ford-Fulkerson)","slug":"最大网络流","date":"2017-07-05T10:04:42.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/07/05/最大网络流/","text":"关于最大网络流算法，网上的教程非常多，可以说形形色色，我个人也稍微做一下总结。网络流算法与背包问题很相似，本质属于线性规划问题。首先需要明确的是容量和流量的两个概念，算法核心思想是从残余图中寻找增广路径直至增广路径不存在（增广路径：一条从源点到宿点的路径，所有的路路径流量为当前最小剩余流量）。穷举试错（DFS、BFS）的过程总是需要“反悔的”，我最开始不假思索想用栈回滚的方式。但Ford-Fulkerson算法很巧妙地利用了方向边，通过反向边的引入实际上实现了回溯。这张图来自谢老师数据挖掘讲义，在此表示感谢。Java实现 public class FordFulkersonDemo { private int[][] Graph; private int[][] f; private int[][] r; private int[] parent; private int source; private int terminal; public FordFulkersonDemo(int Num){ Graph = new int[Num][Num]; f = new int[Num][Num]; r = new int[Num][Num]; parent = new int[Num]; } public FordFulkersonDemo(In in){ this(in.readInt()); for(int i = 0; i &lt; parent.length; i++){ for(int j = 0; j &lt; parent.length; j++){ Graph[i][j] = in.readInt(); } } source = in.readInt(); terminal = in.readInt(); } private void initialization(){ for(int i = 0; i &lt; parent.length; i++){ Arrays.fill(f[i], 0); } } private int[][] residualNetwork(int[][] graph,int[][] f){ int[][] r = new int[parent.length][parent.length]; for(int i = 0; i &lt; parent.length; i++){ for(int j = 0; j &lt; parent.length; j++){ r[i][j] = graph[i][j] - f[i][j]; } } return r; } private int argumentPath(int[][] r,int s,int t){ Arrays.fill(parent, -1); Queue&lt;Integer&gt; q = new LinkedList&lt;Integer&gt;(); int maxFlow = Integer.MAX_VALUE; q.add(s); parent[s] = s; while(!q.isEmpty()){ int v = q.poll(); if(v == t){ while(v != s){ if(maxFlow &gt; r[parent[v]][v]) maxFlow = r[parent[v]][v]; v = parent[v]; } break; } for(int i = 0 ; i &lt; parent.length; i++){ if(i != v &amp;&amp; parent[i] == -1 &amp;&amp; r[v][i] &gt; 0){ parent[i] = v; q.add(i); } } } if(parent[t] == -1){ maxFlow = -1; } return maxFlow; } public int run(){ int sum = 0; initialization(); r = residualNetwork(Graph,f); int result = argumentPath(r,source,terminal); //int cur = terminal; while(result != -1){ int cur = terminal; while(cur != source){ f[parent[cur]][cur] += result; f[cur][parent[cur]] = -f[parent[cur]][cur]; r[parent[cur]][cur] -= result; r[cur][parent[cur]] += result; cur = parent[cur]; } sum += result; // r = residualNetwork(Graph,f); result = argumentPath(r,source,terminal); } return sum; } public static void main(String[] args){ In in = new In(args[0]); FordFulkersonDemo ford = new FordFulkersonDemo(in); System.out.println(ford.run()); } } 在此验证一下程序的效果：程序运行后结果"},{"title":"std::function","slug":"std-function","date":"2017-07-04T09:34:00.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/07/04/std-function/","text":"类模版std::function是一种通用、多态的函数封装。std::function的实例可以对任何可以调用的目标实体进行存储、复制、和调用操作，这些目标实体包括普通函数、Lambda表达式、函数指针、以及其它函数对象等。std::function对象是对C++中现有的可调用实体的一种类型安全的包裹（我们知道像函数指针这类可调用实体，是类型不安全的）。 通常std::function是一个函数对象类，它包装其它任意的函数对象，被包装的函数对象具有类型为T1, …,TN的N个参数，并且返回一个可转换到R类型的值。std::function使用 模板转换构造函数接收被包装的函数对象；特别是，闭包类型可以隐式地转换为std::function。最简单的理解就是： 通过std::function对C++中各种可调用实体（普通函数、Lambda表达式、函数指针、以及其它函数对象等）的封装，形成一个新的可调用的std::function对象；让我们不再纠结那么多的可调用实体。一切变的简单粗暴。 #include #include using namespace std; std::function< int(int)> Functional; // 普通函数 int TestFunc(int a) { return a; } // Lambda表达式 auto lambda = [](int a)->int { return a; }; // 仿函数(functor) class Functor { public: int operator()(int a) { return a; } }; // 1.类成员函数 // 2.类静态函数 class TestClass { public: int ClassMember(int a) { return a; } static int StaticMember(int a) { return a; } }; int main() { // 普通函数 Functional = TestFunc; int result = Functional(10); cout"},{"title":"类加载器","slug":"类加载器","date":"2017-07-02T11:13:19.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/07/02/类加载器/","text":"站在 Java 开发人员的角度来看，类加载器可以大致划分为以下三类： 启动类加载器：Bootstrap ClassLoader，跟上面相同。它负责加载存放在JDK\\jre\\li(JDK 代表 JDK 的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库（如 rt.jar，所有的java.开头的类均被 Bootstrap ClassLoader 加载）。启动类加载器是无法被 Java 程序直接引用的。扩展类加载器：Extension ClassLoader，该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载JDK\\jre\\lib\\ext目录中，或者由 java.ext.dirs 系统变量指定的路径中的所有类库（如javax.开头的类），开发者可以直接使用扩展类加载器。 应用程序类加载器：Application ClassLoader，该类加载器由 sun.misc.Launcher$AppClassLoader 来实现，它负责加载用户类路径（ClassPath）所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。应用程序都是由这三种类加载器互相配合进行加载的，如果有必要，我们还可以加入自定义的类加载器。因为 JVM 自带的 ClassLoader 只是懂得从本地文件系统加载标准的 java class 文件，因此如果编写了自己的 ClassLoader，便可以做到如下几点： *在执行非置信代码之前，自动验证数字签名。 *动态地创建符合用户特定需要的定制化构建类。 *从特定的场所取得 java class，例如数据库中和网络中。 事实上当使用 Applet 的时候，就用到了特定的 ClassLoader，因为这时需要从网络上加载 java class，并且要检查相关的安全信息，应用服务器也大都使用了自定义的 ClassLoader 技术。"},{"title":"弗洛伊德算法及证明","slug":"弗洛伊德算法及证明","date":"2017-07-02T09:45:38.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/07/02/弗洛伊德算法及证明/","text":"弗洛伊德算法属于动态规划问题，通过插点的方式为加权图多源点间寻求最短路径。算法引入两个二维数组path[][]和dist[][],其中dist[i][j]描述两个节点i和j间的最短路径，path[i][j]用来描述节点i和j之间最短路径所经过的节点。首先，初始化非相邻节点dist为INF，得到初始矩阵S，如图所示。在此鸣谢http://www.cnblogs.com/skywang12345所提供的图片依次一各个节点为中介节点，对矩阵S进行更新，规则为若dist[i][j] &gt; dist[i][k]+dist[k][j],则dist[i][j] = dist[i][k] + dist[k][j],path[i][j] = k ,如图所示 根据上述讨论，代码如下 public class FloydDemo { private static int[] matrix; private static int[][] initMatrix; public FloydDemo(int Num,In in){ matrix = new int[Num]; initMatrix = new int[Num][Num]; for(int i = 0; i &lt; matrix.length; i++){ for(int j = 0; j &lt; matrix.length; j++){ initMatrix[i][j] = in.readInt(); } } } public void floyd(int[][] path,int[][] dist){ for(int i = 0; i &lt; matrix.length; i++){ for(int j = 0; j &lt; matrix.length; j++){ dist[i][j] = initMatrix[i][j]; path[i][j] = j; } } for(int k = 0; k &lt; matrix.length; k++){ for(int i = 0; i &lt; matrix.length; i++){ for(int j = 0; j &lt; matrix.length; j++){ if(dist[i][j] &gt; dist[i][k] + dist[k][j]){ dist[i][j] = dist[i][k] + dist[k][j]; path[i][j] = k; } } } } System.out.println(&quot;floyd: \\n&quot;); for (int i = 0; i &lt; matrix.length; i++) { for (int j = 0; j &lt; matrix.length; j++) System.out.printf(&quot;%2d &quot;, dist[i][j]); System.out.printf(&quot;\\n&quot;); } } public static void main(String[] args){ In in = new In(args[0]); int Num = in.readInt(); int[][] path = new int[Num][Num]; int[][] dist = new int[Num][Num]; new FloydDemo(Num,in).floyd(path,dist); } }最终得到多源最短路径矩阵"},{"title":"ODL对packet_in消息的处理流程","slug":"OpenFlowJava处理流程","date":"2017-06-03T13:31:04.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/06/03/OpenFlowJava处理流程/","text":"OpenFlowJava对PakcetIn消息的处理流程 (1)当交换机遇到无法识别，或者需要上报的数据包（reason字段），通过与OpenFlowJava建立连接，向控制器发送消息。(2)OpenFlowJava库对这个数据包进行解析，将解析结果发送给OpenFlowPlugin (3)OpenFlowPlugin将数据包发送给控制器平台，控制器将数据包转发给监听此类数据的网络应用 (4)网络应用根据收到的packet_in消息判断，如果需要将报文广播发送出去，则发送Packet_out消息给控制器 (5)控制器到OpenFlowPlugin (6)OpenFlowPlugin到OpenFlowJava (7)OpenFlowJava将消息序列化之后，通过与交换机的网络连接，将消息发送出去 (8)通过不断的packet_in消息的传送，网络应用学习到网络的拓扑关系，根据拓扑关系组织流表项，并将流表项写入DataStore (9)流规则管理器读取到DataStore的流规则变化之后，读取新加的流表项 (10)流规则管理项读取到的流表项通过RPC调用发送给控制器 (11)控制器根据RPC对应的服务名称找到对应的OpenFlowPlugin，并将流表项发送给OpenFlowPlugin (12)OpenFlowPlugin将消息封装为FlowMod消息，传送给OpenFlowJava (13)OpenFlowJava将消息序列化之后，通过与交换机的网络连接，将消息发送出去"},{"title":"JVM 垃圾回收机制(二)——方法区回收","slug":"JVM-垃圾回收机制-一-——方法区回收","date":"2017-05-13T15:46:01.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/05/13/JVM-垃圾回收机制-一-——方法区回收/","text":"方法区（HotSpot中的永久代）并非没有垃圾回收机制，只是永久代的垃圾回收效率远远低于新生代回收效率。永久代中垃圾回收主要包括两部分：废弃常量和无用的类。回收废弃常量与回收java堆中的对象非常相似，但判断一个类是否是无用的类就比较麻烦，类需要同时满足一下三个条件，才能算是无用的类： 该类所有的实例都已经被回收，即java堆中不存在该类的任何实例。 加载该类的ClassLoader已经被回收。 该类对应的java.lang.Class对象没有任何地方被引用，无法在任何地方通过反射访问该类的方法。 在大量使用反射、动态代理、CGLib等ByteCode框架、动态生成JSP记忆OSGi这类频繁自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代永远不会溢出。 注：可以使用-verbose：class以及-XX:_TraceClassLoading、-XX:TraceClassUnLoading查看类加载和卸载信息"},{"title":"（译）JVM 垃圾回收机制(一)——新生代垃圾回收","slug":"JVM-垃圾回收机制","date":"2017-05-10T14:52:51.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/05/10/JVM-垃圾回收机制/","text":"原作者：PATRICK PESCHLOW 本文对原文有改动 单纯从 JVM 的功能考虑，并不需要新生代，完全可以针对整个堆进行操作。新生代存在的唯一理由是优化垃圾回收 (GC) 的性能。更具体说，把堆划分为新生代和老年代有 2 个好处：简化了新对象的分配 (只在新生代分配内存)， 可以更有效的清除不再需要的对象 (即死对象)(新生代和老年代使用不同的 GC 算法)通过广泛研究面向对象实现的应用，发现一个共同特点：很多对象的生存时间都很短。同时研究发现，新生对象很少引用生存时间长的对象。结合这 2 个特点，很明显 GC 会频繁访问新生对象，例如在堆中一个单独的区域，称之为新生代。在新生代中，GC 可以快速标记回收” 死对象”，而不需要扫描整个 Heap 中的存活一段时间的” 老对象”。 SUN/Oracle 的 HotSpot JVM 又把新生代进一步划分为 3 个区域：一个相对大点的区域，称为“伊甸园区 (Eden)”；两个相对小点的区域称为“From 幸存区 (survivor)” 和“To 幸存区 (survivor)”。按照规定，新对象会首先分配在 Eden 中 (如果新对象过大，会直接分配在老年代中)。在 GC 中，Eden 中的对象会被移动到 survivor 中，直至对象满足一定的年纪 (定义为熬过 GC 的次数)，会被移动到老年代(默认为15岁)。 基于大多数新生对象都会在 GC 中被收回的假设。新生代的 GC 使用复制算法。在 GC 前 To 幸存区 (survivor) 保持清空，对象保存在 Eden 和 From 幸存区 (survivor) 中，GC 运行时，Eden 中的幸存对象被复制到 To 幸存区 (survivor)。针对 From 幸存区 (survivor) 中的幸存对象，会考虑对象年龄，如果年龄没达到阀值 (tenuring threshold)，对象会被复制到 To 幸存区 (survivor)。如果达到阀值对象被复制到老年代。复制阶段完成后，Eden 和 From 幸存区中只保存死对象，可以视为清空。如果在Survivor空间中相同年龄所有对象大小的总和超过了Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。上图演示 GC 过程，黄色表示死对象，绿色表示剩余空间，红色表示幸存对象 总结一下，对象一般出生在 Eden 区，年轻代 GC 过程中，对象在 2 个幸存区之间移动，如果对象存活到适当的年龄，会被移动到老年代。当对象在老年代死亡时，就需要更高级别的 GC，更重量级的 GC 算法 (复制算法不适用于老年代，因为没有多余的空间用于复制) 现在应该能理解为什么新生代大小非常重要了 (译者，有另外一种说法：新生代大小并不重要，影响 GC 的因素主要是幸存对象的数量)，如果新生代过小，会导致新生对象很快就晋升到老年代中，在老年代中对象很难被回收。如果新生代过大，会发生过多的复制过程。我们需要找到一个合适大小，不幸的是，要想获得一个合适的大小，只能通过不断的测试调优。这就需要 JVM 参数了 -XX:NewSize and -XX:MaxNewSize 就像可以通过参数 (-Xms and -Xmx) 指定堆大小一样，可以通过参数指定新生代大小。设置 XX:MaxNewSize 参数时，应该考虑到新生代只是整个堆的一部分，新生代设置的越大，老年代区域就会减少。一般不允许新生代比老年代还大，因为要考虑 GC 时最坏情况，所有对象都晋升到老年代。(译者: 会发生 OOM 错误) -XX:MaxNewSize 最大可以设置为 - Xmx/2。 考虑性能，一般会通过参数 -XX:NewSize 设置新生代初始大小。如果知道新生代初始分配的对象大小 (经过监控)，这样设置会有帮助，可以节省新生代自动扩展的消耗。 -XX:NewRatio 可以设置新生代和老年代的相对大小。这种方式的优点是新生代大小会随着整个堆大小动态扩展。参数 -XX:NewRatio 设置老年代与新生代的比例。例如 -XX:NewRatio=3 指定老年代 / 新生代为 3/1。 老年代占堆大小的 3/4，新生代占 1/4 。 如果针对新生代，同时定义绝对值和相对值，绝对值将起作用。下面例子： $ java -XX:NewSize=32m -XX:MaxNewSize=512m -XX:NewRatio=3 MyApp 以上设置，JVM 会尝试为新生代分配四分之一的堆大小，但不会小于 32MB 或大于 521MB 在设置新生代大小问题上，使用绝对值还是相对值，不存在通用准则 。如果了解应用的内存使用情况， 设置固定大小的堆和新生代更有利，当然也可以设置相对值。如果对应用的内存使用一无所知，正确的做法是不要设置任何参数，如果应用运行良好。很好，我们不用做任何额外动作。如果遇到性能或 OutOfMemoryErrors，在调优之前，首先需要进行一系列有目的的监控测试，缩小问题的根源。 -XX:SurvivorRatio 参数 -XX:SurvivorRatio 与 -XX:NewRatio 类似，作用于新生代内部区域。-XX:SurvivorRatio 指定伊甸园区 (Eden) 与幸存区大小比例。 例如， -XX:SurvivorRatio=10 表示伊甸园区 (Eden) 是 幸存区 To 大小的 10 倍 (也是幸存区 From 的 10 倍)。 所以， 伊甸园区 (Eden) 占新生代大小的 10/12， 幸存区 From 和幸存区 To 每个占新生代的 1/12 。 注意， 两个幸存区永远是一样大的。 设定幸存区大小有什么作用? 假设幸存区相对伊甸园区 (Eden) 太小， 相应新生对象的伊甸园区 (Eden) 永远很大空间， 我们当然希望， 如果这些对象在 GC 时全部被回收， 伊甸园区 (Eden) 被清空， 一切正常。 然而， 如果有一部分对象在 GC 中幸存下来， 幸存区只有很少空间容纳这些对象。 结果大部分幸存对象在一次 GC 后，就会被转移到老年代 ， 这并不是我们希望的。 考虑相反情况， 假设幸存区相对伊甸园区 (Eden) 太大， 当然有足够的空间，容纳 GC 后的幸存对象。 但是过小的伊甸园区 (Eden)， 意味着空间将越快耗尽，增加新生代 GC 次数，这是不可接受的。 总之， 我们希望最小化短命对象晋升到老年代的数量，同时也希望最小化新生代 GC 的次数和持续时间。 我们需要找到针对当前应用的折中方案， 寻找适合方案的起点是 了解当前应用中对象的年龄分布情况。 -XX:+PrintTenuringDistribution 参数 -XX:+PrintTenuringDistribution 指定 JVM 在每次新生代 GC 时，输出幸存区中对象的年龄分布。例如: Desired survivor size 75497472 bytes， new threshold 15 (max 15)age 1: 19321624 bytes， 19321624 totalage 2: 79376 bytes， 19401000 totalage 3: 2904256 bytes， 22305256 total第一行说明幸存区 To 大小为 75 MB。 也有关于老年代阀值 (tenuring threshold) 的信息， 老年代阀值，意思是对象从新生代移动到老年代之前，经过几次 GC(即， 对象晋升前的最大年龄)。 上例中， 老年代阀值为 15， 最大也是 15。 之后行表示，对于小于老年代阀值的每一个对象年龄，本年龄中对象所占字节 (如果当前年龄没有对象， 这一行会忽略)。 上例中， 一次 GC 后幸存对象大约 19 MB， 两次 GC 后幸存对象大约 79 KB，三次 GC 后幸存对象大约 3 MB 。 每行结尾，显示直到本年龄全部对象大小。 所以， 最后一行的 total 表示幸存区 To 总共被占用 22 MB 。 幸存区 To 总大小为 75 MB ， 当前老年代阀值为 15，可以断定在本次 GC 中，没有对象会移动到老年代。现在假设下一次 GC 输出为： Desired survivor size 75497472 bytes， new threshold 2 (max 15)age 1: 68407384 bytes， 68407384 totalage 2: 12494576 bytes， 80901960 totalage 3: 79376 bytes， 80981336 totalage 4: 2904256 bytes， 83885592 total对比前一次老年代分布。明显的， 年龄 2 和年龄 3 的对象还保持在幸存区中，因为我们看到年龄 3 和 4 的对象大小与前一次年龄 2 和 3 的相同。同时发现幸存区中， 有一部分对象已经被回收， 因为本次年龄 2 的对象大小为 12MB ，而前一次年龄 1 的对象大小为 19 MB。最后可以看到最近的 GC 中，有 68 MB 新对象，从伊甸园区移动到幸存区。 注意， 本次 GC 幸存区占用总大小 84 MB - 大于 75 MB。 结果， JVM 把老年代阀值从 15 降低到 2，在下次 GC 时，一部分对象会强制离开幸存区，这些对象可能会被回收 (如果他们刚好死亡) 或移动到老年代。 -XX:InitialTenuringThreshold， -XX:MaxTenuringThreshold and -XX:TargetSurvivorRatio 参数 -XX:+PrintTenuringDistribution 输出中的部分值可以通过其它参数控制。通过 -XX:InitialTenuringThreshold 和 -XX:MaxTenuringThreshold 可以设定老年代阀值的初始值和最大值。另外， 可以通过参数 -XX:TargetSurvivorRatio 设定幸存区的目标使用率。 例如， -XX:MaxTenuringThreshold=10 -XX:TargetSurvivorRatio=90 设定老年代阀值的上限为 10， 幸存区空间目标使用率为 90%。 有多种方式， 设置新生代行为，没有通用准则。我们必须清楚以下 2 中情况： 如果从年龄分布中发现，有很多对象的年龄持续增长，在到达老年代阀值之前。这表示 -XX:MaxTenuringThreshold 设置过大 如果 -XX:MaxTenuringThreshold 的值大于 1，但是很多对象年龄从未大于 1。应该看下幸存区的目标使用率。如果幸存区使用率从未到达，这表示对象都被 GC 回收，这正是我们想要的。 如果幸存区使用率经常达到，有些年龄超过 1 的对象被移动到老年代中。这种情况，可以尝试调整幸存区大小或目标使用率。-XX:+NeverTenure and -XX:+AlwaysTenure 最后，我们介绍 2 个颇为少见的参数，对应 2 种极端的新生代 GC 情况。设置参数 -XX:+NeverTenure，对象永远不会晋升到老年代。当我们确定不需要老年代时，可以这样设置。这样设置风险很大， 并且会浪费至少一半的堆内存。相反设置参数 -XX:+AlwaysTenure，表示没有幸存区，所有对象在第一次 GC 时，会晋升到老年代。 没有合理的场景使用这个参数。可以在测试环境中，看下这样设置会发生什么有趣的事。但是并不推荐使用这些参数。 结论 适当的配置新生代非常重要，有相当多的参数可以设置新生代。然而，单独调整新生代，而不考虑老年代是不可能优化成功的。当调整堆和 GC 设置时，我们总是应该同时考虑新生代和老年代。"},{"title":"容器技术与虚拟机","slug":"容器技术与虚拟机","date":"2017-05-04T06:14:48.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/05/04/容器技术与虚拟机/","text":"云计算的本质是集中资源再分配，再分配的过程就是资源的逻辑划分，提供资源抽象的实现方式。其中主要涉及两个方面，资源控制和资源隔离。 居然一直都无法准确表述镜像的概念，所谓镜像，包括各种打包的Apps、系统使用进程、应用软件、shell以及公用函数库。 虚拟机 虚拟机的Guest OS即为虚拟机安装的操作系统，它是一个完整操作系统内核；虚拟机的Hypervisor层可以简单理解为一个硬件虚拟化平台(VMW、VirtualBox)，它在Host OS是以内核态的驱动存在的。虚拟机实现资源隔离的方法是利用独立的OS，并利用Hypervisor虚拟化CPU、内存、IO设备等实现的。 为了虚拟CPU，Hypervisor会为每个虚拟的CPU创建一个数据结构，模拟CPU的全部寄存器的值，在适当的时候跟踪并修改这些值。需要指出的是在大多数情况下，虚拟机软件代码是直接跑在硬件上的，而不需要Hypervisor介入。只有在一些权限高的请求下，Guest OS需要运行内核态修改CPU的寄存器数据，Hypervisor会介入，修改并维护虚拟的CPU状态。 Hypervisor虚拟化内存的方法是创建一个shadow page table。正常的情况下，一个page table可以用来实现从虚拟内存到物理内存的翻译。在虚拟化的情况下，由于所谓的物理内存仍然是虚拟的，因此shadow page table就要做到：虚拟内存-&gt;虚拟的物理内存-&gt;真正的物理内存。 对于IO设备虚拟化，当Hypervisor接到page fault，并发现实际上虚拟的物理内存地址对应的是一个I/O设备，Hypervisor就用软件模拟这个设备的工作情况，并返回。比如当CPU想要写磁盘时，Hypervisor就把相应的数据写到一个host OS的文件上，这个文件实际上就模拟了虚拟的磁盘。 Docker容器技术的出现远远早于Docker，Docker只是提供了一个能够方便管理容器的工具并为其提供了标准。Docker相当于把应用以及应用所依赖的环境完整打成一个包，这个包不管拿到哪里都能够原生运行。 docker Engine可以简单看成对Linux的NameSpace、Cgroup、镜像管理文件系统操作的封装。docker并没有和虚拟机一样利用一个完全独立的Guest OS实现环境隔离，它利用的是目前Linux内核本身支持的容器方式,主要是Namespace和CGroup来实现资源和环境隔离。其中namespace实现系统环境的隔离，Cgroup实现资源限制，而利用镜像实现根目录环境的隔离。 通过docker和虚拟机实现原理的比较，我们大致可以得出一些结论： docker有着比虚拟机更少的抽象层。由于docker不需要Hypervisor实现硬件资源虚拟化，运行在docker容器上的程序直接使用的都是实际物理机的硬件资源。因此在CPU、内存利用率上docker将会在效率上有优势。在IO设备虚拟化上，docker的镜像管理有多种方案，比如利用Aufs文件系统或者Device Mapper实现docker的文件管理，各种实现方案的效率略有不同。 docker利用的是宿主机的内核，而不需要Guest OS。因此，当新建一个容器时，docker不需要和虚拟机一样重新加载一个操作系统内核。我们知道，引导、加载操作系统内核是一个比较费时费资源的过程，当新建一个虚拟机时，虚拟机软件需要加载Guest OS，这个新建过程是分钟级别的。而docker由于直接利用宿主机的操作系统，则省略了这个过程，因此新建一个docker容器只需要几秒钟。另外，现代操作系统是复杂的系统，在一台物理机上新增加一个操作系统的资源开销是比较大的，因此，docker对比虚拟机在资源消耗上也占有比较大的优势。事实上，在一台物理机上我们可以很容易建立成百上千的容器，而只能建立几个虚拟机。 CGroup与Namespace CGroup将一组进程放在一个控制组里，通过给这个控制组分配指定的可用资源，达到控制这一组进程可用资源的目的。 NamespaceNamespace是将内核的全局资源做封装，使得每个Namespace都有一份独立的资源，因此不同的进程在各自的Namespace内对同一种资源的实用不会相互干扰。Linux总共实现了6种Namespace： IPC：隔离System VIPC和POSIX消息队列 Network ： 隔离网络资源 Mount 隔离文件系统挂载点 PID ：隔离进程ID UTS ：隔离主机名和域名 User ：隔离用户ID和组ID 容器 = CGroup + NameSpace+rootfs+容器引擎 rootfs：文件隔离控制容器引擎： 生命周期控制 Docker与虚拟机的优劣 虚拟机 由于虚拟机镜像必须依赖于Guest OS这一庞大的内核，因此十分臃肿，无法在一台物理主机上大量建立 由于虚拟机启动前必须先启动Guest OS,因此，创建和启动的时间开销大 使用虚拟资源会存在资源损耗 部署密度小 Docker优势 镜像体积小，只包括apps以及所依赖的环境，没有内核 创建启动时间开销小 没有Guest OS和hypervisor，无额外资源开销，资源控制粒度小，部署密度大 使用的是真实的物力资源，不存在资源损耗 Docker劣势docker的劣势 资源隔离方面不如虚拟机，docker是利用cgroup实现资源限制的，只能限制资源消耗的最大值，而不能隔绝其他程序占用自己的资源。 安全性问题。docker目前并不能分辨具体执行指令的用户，只要一个用户拥有执行docker的权限，那么他就可以对docker的容器进行所有操作，不管该容器是否是由该用户创建。比如A和B都拥有执行docker的权限，由于docker的server端并不会具体判断docker cline是由哪个用户发起的，A可以删除B创建的容器，存在一定的安全风险。 docker目前还在版本的快速更新中，细节功能调整比较大。一些核心模块依赖于高版本内核，存在版本兼容问题"},{"title":"春华秋实","slug":"春华秋实","date":"2017-05-03T10:31:33.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/05/03/春华秋实/","text":""},{"title":"斐波那契堆","slug":"斐波那契堆","date":"2017-05-02T05:10:07.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/05/02/斐波那契堆/","text":"一个斐波那契堆具有如下性质： 堆有一组有序树组成，但是堆中的树不一定是二项树 斐波那契堆中的树之间是无序的（二项堆中的树是按照其包含的二项树的度数排序的） 堆中每个节点的数据结构包含如下域： 指向其父节点的指针域 指向其任意一个孩子的指针域 任意一个节点x的所有孩子被链接在一个双向链表环形链表中 节点x中保存有它的孩子的数目degree 节点x中存在一个域mark，用于表示自从x上一次称为另一个节点的子女以来，它是否失掉了一个孩子，TRUE表示是失去了，FALSE表示未失去斐波那契堆中的所有树的树根被保存在一个链表即根表中对于一个斐波那契堆，min[H]保存了具有最小节点值的根节点在计算机科学中，斐波那契堆是由树的集合所组成的堆数据结构。它比二项堆的平摊运行时间更好。斐波那契堆的名字来自于斐波那契数列，这些数列被用来做运行时间分析。 求最小值(find-mininum), 插入(insert), 降低元素值(decrease-key)和合并(merge/union)可以在常数平摊时间内完成。删除(delete)和删除最小值(delete minimun)可以在O(log n)平摊时间内完成。 在优先队列(priority queues)中使用斐波那契堆可以提升重要算法的渐进运行时间，例如Dijkstra算法，该算法用来计算一个图中两个结点的最短的距离。 斐波那契堆是由一些树的集合所组成，其中每一棵树都满足最小堆(minimum-heap)的属性，也就是说树中每个子结点的值都大于或者等于其父结点的值，而最小值则处在根结点上。 与二项堆不同，斐波那契堆中的树更加灵活，没有规定的形状，在极端情况下，堆中每个元素都是一棵单独的树。这种灵活性使得一些操作可以以“偷懒”的方式来执行，而“剩下”的工作将推迟到后面的操作中来完成。比如堆的合并仅仅将由树所组成的链表链接起来，而降低元素值(decrease key)有时直接从父结点中剪断而形成一棵新树。 下面给出斐波那契堆中关键的量值： degree[x]:degree[x]: 表示结点x的子结点个数 mark[x]:mark[x]: 一个结点是否被marked了（当执行decrease key操作时会用到） t(H):t(H): 表示堆中树的个数 m(H):m(H): 表示被marked的结点数量 Φ(H)=t(H)+2m(H):Φ(H)=t(H)+2m(H): 表示势函数 如下图所示：从图中可以看出，一共有5棵树，即t(H)=5t(H)=5，最小值的指针指向元素值为3的根结点，在这棵包含最小值的树中，根结点有3个子结点，所以其degree等于3，整个斐波那契堆用 H 来表示。其中黑色表示被marked了，灰色表示没有被marked，所以m(H)=3m(H)=3，势函数 Φ(H)=t(H)+2m(H)=5+2∗3=11Φ(H)=t(H)+2m(H)=5+2∗3=11 Make-Fibonacci-Heap() n[H] := 0 min[H] := NIL return H Fibonacci-Heap-Minimum(H) return min[H] Fibonacci-Heap-Link(H,y,x) remove y from the root list of H make y a child of x degree[x] := degree[x] + 1 mark[y] := FALSE CONSOLIDATE(H) for i:=0 to D(n[H]) Do A[i] := NIL for each node w in the root list of H do x:= w d:= degree[x] while A[d] NIL do y:=A[d] if key[x]>key[y] then exchange xy Fibonacci-Heap-Link(H, y, x) A[d]:=NIL d:=d+1 A[d]:=x min[H]:=NIL for i:=0 to D(n[H]) do if A[i] NIL then add A[i] to the root list of H if min[H] = NIL or key[A[i]]"},{"title":"Latch","slug":"Latch","date":"2017-04-28T07:40:52.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/04/28/Latch/","text":"#Latch 同步工具类除了最熟悉的阻塞队列之外，还包括Semaphore、Barrier以及Latch。同样，我们也可以创建属于自己的同步工具类。所有的同步工具类都包含了一些特定的结构属性：比如，封装了一些状态，而这些状态将决定执行同步工具类的线程是继续执行还是等待，除此而外，还提供了一些方法对状态进行操作，以及高效的等待同步工具类进入到预期的状态。闭锁最形象的比喻是一扇Gate，在闭锁到达结束状态之前，这扇门始终处于关闭的状态，任何线程都无法通过。而当闭锁到达结束状态，这扇门将打开，进而允许所有的线程通过。一旦闭锁达到结束状态，这扇门将保持打开的状态，不会再关闭。换句话说，闭锁的作用是保持某些活动直到其他活动都完成才继续执行。举个例子，我们都知道并发在某些情况下，可以极大地提升工作效率，缩短程序的运行时间，那么我们该如何去获取并发程序准确的运行时间，即在所有线程全部就绪的时刻启动时间，而在所有线程全部结束的时刻终止时间。Latch可以做到，看下面程序。 public class TestHarness { public static String timeTask(int nThreads,final Runnable[] tasks) throws InterruptedException{ final CountDownLatch startGate=new CountDownLatch(1); final CountDownLatch endGate=new CountDownLatch(nThreads); for(Runnable task:tasks){ Thread t=new Thread(){ public void run(){ try{ startGate.await(); try{ task.run(); }finally{ //每个线程最终最后执行将endGate减1 endGate.countDown(); } }catch(InterruptedException e){ } } }; t.start(); } long startTime=System.nanoTime(); startGate.countDown(); endGate.await(); long endTime=System.nanoTime(); return \"Time: \"+(endTime-startTime)+\"ns\"; } 由于startGate被设置为等待 startGate.await(); 因此每个线程首先要做的工作就是在启动门上等待，直到所有的线程全部就绪。并且，我们在为每个线程装载任务时 finally{endGate.countDown();} 保证没个线程最终都会执行使得endGate减1的任务 startGate.countDown(); 注意startGate的初值为1，因此调用countDown方法后，门打开，此时线程开始执行 endGate.await(); endGate此时关闭，要做的工作就是等待且为零的时刻，然后打开 如果没用使用Latch工具而去获取并行线程的运行时间，线程在被创建之后将立即执行，显然，先启动的线程势必会领先于后启动的线程，并且活跃线程的数量会随着时间的推移而慢慢减少或者增加，竞争程度也将发生变化。有了这个工具，我们今后在编写并发程序是，只需要调用timeTasks函数，并向其传递任务参数，就可以获取并发时间了。"},{"title":"五月任务计划","slug":"五月任务计划","date":"2017-04-28T04:59:25.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/04/28/五月任务计划/","text":"###技术目标 深入研究OSGi，理解java模块化编程，以及OSGi如何打破类加载机制的双亲委派模型 预期目标：开发一个Opendaylight可用的Bundle，具体功能为获取网络拓普信息并建路 结合Spring技术内幕一书，研究Spring源码，并以此进一步锤炼java 尝试编译OpenJDK ###论文目标 5号之间将论文搞定 15号之前完成论文翻译工作 ####出行 争取在月内和女神实现厦门行"},{"title":"synchronized关键字","slug":"synchronized关键字","date":"2017-04-28T04:24:43.000Z","comments":true,"permalink":"http://www.lex-zhao.xyz/2017/04/28/synchronized关键字/","text":"在并发编程中，多线程同时并发访问的资源叫做临界资源，当多个线程同时访问对象并要求操作相同资源时，分割了原子操作就有可能出现数据的不一致或数据不完整的情况，为避免这种情况的发生，我们会采取同步机制，以确保在某一时刻，方法内只允许有一个线程。 采用 synchronized 修饰符实现的同步机制叫做互斥锁机制，它所获得的锁叫做互斥锁。每个对象都有一个 monitor (锁标记)，当线程拥有这个锁标记时才能访问这个资源，没有锁标记便进入锁池。任何一个对象系统都会为其创建一个互斥锁，这个锁是为了分配给线程的，防止打断原子操作。每个对象的锁只能分配给一个线程，因此叫做互斥锁。这里就使用同步机制获取互斥锁的情况，进行几点说明： 1、如果同一个方法内同时有两个或更多线程，则每个线程有自己的局部变量拷贝。 2、类的每个实例都有自己的对象级别锁。当一个线程访问实例对象中的 synchronized 同步代码块或同步方法时，该线程便获取了该实例的对象级别锁，其他线程这时如果要访问 synchronized 同步代码块或同步方法，便需要阻塞等待，直到前面的线程从同步代码块或方法中退出，释放掉了该对象级别锁。 3、访问同一个类的不同实例对象中的同步代码块，不存在阻塞等待获取对象锁的问题，因为它们获取的是各自实例的对象级别锁，相互之间没有影响。 4、持有一个对象级别锁不会阻止该线程被交换出来，也不会阻塞其他线程访问同一示例对象中的非 synchronized 代码。当一个线程 A 持有一个对象级别锁（即进入了 synchronized 修饰的代码块或方法中）时，线程也有可能被交换出去，此时线程 B 有可能获取执行该对象中代码的时间，但它只能执行非同步代码（没有用 synchronized 修饰），当执行到同步代码时，便会被阻塞，此时可能线程规划器又让 A 线程运行，A 线程继续持有对象级别锁，当 A 线程退出同步代码时（即释放了对象级别锁），如果 B 线程此时再运行，便会获得该对象级别锁，从而执行 synchronized 中的代码。 5、持有对象级别锁的线程会让其他线程阻塞在所有的 synchronized 代码外。例如，在一个类中有三个synchronized 方法 a，b，c，当线程 A 正在执行一个实例对象 M 中的方法 a 时，它便获得了该对象级别锁，那么其他的线程在执行同一实例对象（即对象 M）中的代码时，便会在所有的 synchronized 方法处阻塞，即在方法 a，b，c 处都要被阻塞，等线程 A 释放掉对象级别锁时，其他的线程才可以去执行方法 a，b 或者 c 中的代码，从而获得该对象级别锁。 6、使用 synchronized（obj）同步语句块，可以获取指定对象上的对象级别锁。obj 为对象的引用，如果获取了 obj 对象上的对象级别锁，在并发访问 obj 对象时时，便会在其 synchronized 代码处阻塞等待，直到获取到该 obj对象的对象级别锁。当 obj 为 this 时，便是获取当前对象的对象级别锁。 7、类级别锁被特定类的所有示例共享，它用于控制对 static 成员变量以及 static 方法的并发访问。具体用法与对象级别锁相似。 8、互斥是实现同步的一种手段，临界区、互斥量和信号量都是主要的互斥实现方式。synchronized 关键字经过编译后，会在同步块的前后分别形成 monitorenter 和 monitorexit 这两个字节码指令。根据虚拟机规范的要求，在执行 monitorenter 指令时，首先要尝试获取对象的锁，如果获得了锁，把锁的计数器加 1，相应地，在执行 monitorexit 指令时会将锁计数器减 1，当计数器为 0 时，锁便被释放了。由于 synchronized 同步块对同一个线程是可重入的，因此一个线程可以多次获得同一个对象的互斥锁，同样，要释放相应次数的该互斥锁，才能最终释放掉该锁。"}]}