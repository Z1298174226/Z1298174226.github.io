<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>倾听枫声</title>
  <subtitle>lexzhao</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.lexzhao.top/"/>
  <updated>2019-01-18T16:03:55.992Z</updated>
  <id>http://www.lexzhao.top/</id>
  
  <author>
    <name>倾听枫声</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Thread.interrupt()源码剖析</title>
    <link href="http://www.lexzhao.top/2019/01/18/Thread-interrupt-%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/"/>
    <id>http://www.lexzhao.top/2019/01/18/Thread-interrupt-源码剖析/</id>
    <published>2019-01-18T15:32:38.000Z</published>
    <updated>2019-01-18T16:03:55.992Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1、如何终止一个Java线程&quot;&gt;&lt;a href=&quot;#1、如何终止一个Java线程&quot; class=&quot;headerlink&quot; title=&quot;1、如何终止一个Java线程&quot;&gt;&lt;/a&gt;1、如何终止一个Java线程&lt;/h2&gt;&lt;p&gt;Java线程的终止操作最初是直接暴露给用户的，java.lang.Thread类提供了stop()方法，允许用户暴力的终止一个线程并退出临界区（释放所有锁，并在当前调用栈抛出ThreadDeath Exception）。同样的，Thread.suspend()和Thread.resume()方法允许用户灵活的暂停和恢复线程。&lt;/p&gt;
&lt;p&gt;然而这些看似简便的API在JDK1.2就被deprecate掉了，原因是stop()方法本质上是不安全的，它会强制释放掉线程持有的锁，这样临界区的数据中间状态就会遗留出来，从而造成不可预知的后果。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="java" scheme="http://www.lexzhao.top/tags/java/"/>
    
      <category term="concurrent" scheme="http://www.lexzhao.top/tags/concurrent/"/>
    
  </entry>
  
  <entry>
    <title>线程池拒绝策略</title>
    <link href="http://www.lexzhao.top/2018/10/02/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%8B%92%E7%BB%9D%E7%AD%96%E7%95%A5/"/>
    <id>http://www.lexzhao.top/2018/10/02/线程池拒绝策略/</id>
    <published>2018-10-02T10:53:36.000Z</published>
    <updated>2018-10-02T10:54:20.230Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;(1) 默认的ThreadPoolExecutor.AbortPolicy   处理程序遭到拒绝将抛出运行时RejectedExecutionException;&lt;br&gt;(2) ThreadPoolExecutor.CallerRunsPolicy 线程调用运行该任务的 e
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="java" scheme="http://www.lexzhao.top/tags/java/"/>
    
      <category term="Concurrent" scheme="http://www.lexzhao.top/tags/Concurrent/"/>
    
  </entry>
  
  <entry>
    <title>设计模式六大原则</title>
    <link href="http://www.lexzhao.top/2018/10/02/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%85%AD%E5%A4%A7%E5%8E%9F%E5%88%99/"/>
    <id>http://www.lexzhao.top/2018/10/02/设计模式六大原则/</id>
    <published>2018-10-02T10:52:04.000Z</published>
    <updated>2018-10-02T10:58:02.184Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;开闭原则：一个软件实体，如类、模块和函数应该对扩展开放，对修改关闭&lt;br&gt;单一职责原则：一个类只负责一项职责&lt;br&gt;里式替换原则&lt;br&gt;接口隔离原则：客户端不应该依赖它不需要的接口，一个类对另一个类的依赖应该建立在最小的接口上&lt;br&gt;依赖倒置原则：高层模块不应该依赖底层模块
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="java" scheme="http://www.lexzhao.top/tags/java/"/>
    
      <category term="设计模式" scheme="http://www.lexzhao.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>观察者模式与监听模式</title>
    <link href="http://www.lexzhao.top/2018/10/02/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E4%B8%8E%E7%9B%91%E5%90%AC%E6%A8%A1%E5%BC%8F/"/>
    <id>http://www.lexzhao.top/2018/10/02/观察者模式与监听模式/</id>
    <published>2018-10-02T10:51:54.000Z</published>
    <updated>2018-10-02T10:57:24.963Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;事件和消息的区别&lt;br&gt;事件本身即是具有特定业务含义的一种固定结构对象，而消息是数据传输过程中的载体。概念上宽泛来讲，事件可以称作是一种消息，而消息不能代替事件。事件反映的是特定的业务状态，比如订单创建、服务调用失败、应用宕机等。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="java" scheme="http://www.lexzhao.top/tags/java/"/>
    
      <category term="设计模式" scheme="http://www.lexzhao.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>装饰模式与组合模式</title>
    <link href="http://www.lexzhao.top/2018/10/02/%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F%E4%B8%8E%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F/"/>
    <id>http://www.lexzhao.top/2018/10/02/装饰模式与组合模式/</id>
    <published>2018-10-02T10:51:39.000Z</published>
    <updated>2018-10-02T10:56:30.291Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;装饰者模式可以用来透明地把对象包装在具有同样接口的另一个对象中。这样一来，你可以给一个方法加一些行为，然后将方法调用传递给原始对象。&lt;br&gt;component&lt;br&gt;concrete component&lt;br&gt;decorator&lt;br&gt;concrete decorator&lt;br&gt;相对于创建子类来说，使用装饰者对象是一种更灵活的选择。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="java" scheme="http://www.lexzhao.top/tags/java/"/>
    
      <category term="设计模式" scheme="http://www.lexzhao.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>均方差和交叉熵</title>
    <link href="http://www.lexzhao.top/2018/10/02/%E5%9D%87%E6%96%B9%E5%B7%AE%E5%92%8C%E4%BA%A4%E5%8F%89%E7%86%B5/"/>
    <id>http://www.lexzhao.top/2018/10/02/均方差和交叉熵/</id>
    <published>2018-10-02T10:38:54.000Z</published>
    <updated>2018-10-02T10:43:29.359Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;当使用sigmoid函数作为激活函数时，最好使用交叉熵作为损失函数，避免收敛速度过慢&lt;br&gt;均方差在误差较大时候惩罚力度大，不适合作为分类问题&lt;br&gt;在机器学习中，希望算法或者网络收敛更快，有些是对数据预处理，尤其是Batch Normalization，有些是采用不同的激
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="神经网络" scheme="http://www.lexzhao.top/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="DNN" scheme="http://www.lexzhao.top/tags/DNN/"/>
    
  </entry>
  
  <entry>
    <title>谈谈深度学习中的Batch_size</title>
    <link href="http://www.lexzhao.top/2018/10/02/%E8%B0%88%E8%B0%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84Batch-size/"/>
    <id>http://www.lexzhao.top/2018/10/02/谈谈深度学习中的Batch-size/</id>
    <published>2018-10-02T10:38:36.000Z</published>
    <updated>2018-10-02T10:44:55.606Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Batch_Size（批尺寸）是机器学习中一个重要参数，涉及诸多矛盾，下面逐一展开。&lt;/p&gt;
&lt;p&gt;首先，为什么需要有 Batch_Size 这个参数？&lt;br&gt;Batch 的选择，首先决定的是下降的方向。如果数据集比较小，完全可以采用全数据集 （ Full Batch Learning ）的形式，这样做至少有 2 个好处：其一，由全数据集确定的方向能够更好地代表样本总体，从而更准确地朝向极值所在的方向。其二，由于不同权重的梯度值差别巨大，因此选取一个全局的学习率很困难。 Full Batch Learning 可以使用 Rprop 只基于梯度符号并且针对性单独更新各权值。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="神经网络" scheme="http://www.lexzhao.top/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="DNN" scheme="http://www.lexzhao.top/tags/DNN/"/>
    
  </entry>
  
  <entry>
    <title>对几句话的思考</title>
    <link href="http://www.lexzhao.top/2018/10/02/%E5%AF%B9%E5%87%A0%E5%8F%A5%E8%AF%9D%E7%9A%84%E6%80%9D%E8%80%83/"/>
    <id>http://www.lexzhao.top/2018/10/02/对几句话的思考/</id>
    <published>2018-10-02T10:38:14.000Z</published>
    <updated>2018-10-02T10:42:12.372Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;神经网络本质是函数逼近器(万能逼近定理表明一个前馈神经网络如果具有线性输出层和多层的具有“挤压”性质的激活函数的隐藏层，只要给予这个网络足够数量的隐藏单元，那么它能任意精度地逼近从一个有限维空间到另一个有限维空间的Borel可测函数,借此理解为什么隐藏层层数越多，逼近能力越
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="神经网络" scheme="http://www.lexzhao.top/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="DNN" scheme="http://www.lexzhao.top/tags/DNN/"/>
    
  </entry>
  
  <entry>
    <title>Batch Normalization学习笔记</title>
    <link href="http://www.lexzhao.top/2018/10/02/Batch-Normalization%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.lexzhao.top/2018/10/02/Batch-Normalization学习笔记/</id>
    <published>2018-10-02T10:38:01.000Z</published>
    <updated>2018-10-02T10:44:35.779Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;BN层的作用&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;（1）加速收敛 &lt;/p&gt;
&lt;p&gt;（2）控制过拟合，可以少用或不用Dropout和正则 &lt;/p&gt;
&lt;p&gt;（3）降低网络对初始化权重不敏感&lt;/p&gt;
&lt;p&gt;（4）允许使用较大的学习率&lt;br&gt;&lt;/p&gt;&lt;/blockquote&gt;
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="神经网络" scheme="http://www.lexzhao.top/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="DNN" scheme="http://www.lexzhao.top/tags/DNN/"/>
    
  </entry>
  
  <entry>
    <title>万能（通用）逼近定理</title>
    <link href="http://www.lexzhao.top/2018/10/02/%E4%B8%87%E8%83%BD%EF%BC%88%E9%80%9A%E7%94%A8%EF%BC%89%E9%80%BC%E8%BF%91%E5%AE%9A%E7%90%86/"/>
    <id>http://www.lexzhao.top/2018/10/02/万能（通用）逼近定理/</id>
    <published>2018-10-02T10:37:26.000Z</published>
    <updated>2018-10-02T10:44:20.052Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;万能逼近定理表明一个前馈神经网络如果具有线性输出层和多层的具有“挤压”性质的激活函数的隐藏层，只要给予这个网络足够数量的隐藏单元，那么它能任意精度地逼近从一个有限维空间到另一个有限维空间的Borel可测函数,借此理解为什么隐藏层层数越多，逼近能力越强（不考虑overfitting）（类比泰勒级数展开，我猜的）&lt;br&gt;意味着神经网络具有任意的表示能力，但也只能存在式的证明&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="神经网络" scheme="http://www.lexzhao.top/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="DNN" scheme="http://www.lexzhao.top/tags/DNN/"/>
    
  </entry>
  
  <entry>
    <title>弹性反向传播(RProp)和均方根反向传播(RMSProp)</title>
    <link href="http://www.lexzhao.top/2018/10/02/%E5%BC%B9%E6%80%A7%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD-RProp-%E5%92%8C%E5%9D%87%E6%96%B9%E6%A0%B9%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD-RMSProp/"/>
    <id>http://www.lexzhao.top/2018/10/02/弹性反向传播-RProp-和均方根反向传播-RMSProp/</id>
    <published>2018-10-02T10:37:02.000Z</published>
    <updated>2018-10-02T10:44:06.973Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Rprop&lt;br&gt;为个权重变化附一个初始值，设定权重变化加速因子与减速因子&lt;br&gt;在网络前馈迭代中当连续误差梯度符号不变时，采用加速策略，加快训练速度；当连续误差梯度符号变化时，采用减速策略，以期稳定收敛。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="神经网络" scheme="http://www.lexzhao.top/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="DNN" scheme="http://www.lexzhao.top/tags/DNN/"/>
    
  </entry>
  
  <entry>
    <title>生成式对抗网</title>
    <link href="http://www.lexzhao.top/2018/10/02/%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91/"/>
    <id>http://www.lexzhao.top/2018/10/02/生成式对抗网/</id>
    <published>2018-10-02T09:58:31.000Z</published>
    <updated>2018-10-02T10:10:10.663Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;14年Goodfellow提出Generative adversarial nets即生成式对抗网络[5]，它要解决的问题是如何从训练样本中学习出新样本，训练样本是图片就生成新图片，训练样本是文章就输出新文章等等。如果能够知道训练样本的分布p(x)，那么就可以在分布中随机采样得到新样本，大部分的生成式模型都采用这种思路，GAN则是在学习从随机变量z到训练样本x的映射关系，其中随机变量可以选择服从正太分布，那么就能得到一个由多层感知机组成的生成网络G(z;θg)，网络的输入是一个一维的随机变量，输出是一张图片。如何让输出的伪造图片看起来像训练样本，Goodfellow采用了这样一种方法，在生成网络后面接上一个多层感知机组成的判别网络D(x;θd)，这个网络的输入是随机选择一张真实样本或者生成网络的输出，输出是输入图片来自于真实样本pdata或者生成网络pg的概率，当判别网络能够很好的分辨出输入是不是真实样本时，也能通过梯度的方式说明什么样的输入更加像真实样本，从而通过这个信息来调整生成网络。从而G需要尽可能的让自己的输出像真实样本，而D则尽可能的将不是真实样本的情况分辨出来。下图左边是GAN算法的概率解释，右边是模型构成。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="神经网络" scheme="http://www.lexzhao.top/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="生成式对抗网" scheme="http://www.lexzhao.top/tags/%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91/"/>
    
  </entry>
  
  <entry>
    <title>深度生成模型预算法</title>
    <link href="http://www.lexzhao.top/2018/10/02/%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E9%A2%84%E7%AE%97%E6%B3%95/"/>
    <id>http://www.lexzhao.top/2018/10/02/深度生成模型预算法/</id>
    <published>2018-10-02T09:54:08.000Z</published>
    <updated>2018-10-02T10:09:50.797Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Generative Adversarial Nets,核心思想是从训练样本中学习所对应的概率分布，来期望根据概率分布函数获取更多的生成样本来实现数据的扩张。包括两个子网络模型：&lt;br&gt;生成模型：使得生成的“伪”图像尽可能与“自然”图像的分布一致&lt;br&gt;判别模型：在生成的“伪”图像和“自然”图像之间做出正确的判断，即二类分类器&lt;br&gt;实现整个网络训练的方法便是让着两个网络相互竞争，最终生成模型通过学习“自然”数据的本质特性，从而刻画出“自然”样本的分布概率，生成与“自然”样本相似的新数据&lt;/p&gt;
&lt;p&gt;类似于二人博弈的感觉，零和博弈问题（纳什平衡）&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="神经网络" scheme="http://www.lexzhao.top/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="生成式对抗网" scheme="http://www.lexzhao.top/tags/%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91/"/>
    
  </entry>
  
  <entry>
    <title>Jensen-Shannon散度</title>
    <link href="http://www.lexzhao.top/2018/10/02/Jensen-Shannon%E6%95%A3%E5%BA%A6/"/>
    <id>http://www.lexzhao.top/2018/10/02/Jensen-Shannon散度/</id>
    <published>2018-10-02T09:54:08.000Z</published>
    <updated>2018-10-02T10:09:29.280Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;KL散度（Kullback-Leibler divergence）&lt;br&gt;在概率论或信息论中，KL散度( Kullback–Leibler divergence)，又称相对熵（relative entropy)，是描述两个概率分布P和Q差异的一种方法。它是非对称的，这意味着D(P||Q) ≠ D(Q||P)。特别的，在信息论中，D(P||Q)表示当用概率分布Q来拟合真实分布P时，产生的信息损耗，其中P表示真实分布，Q表示P的拟合分布。&lt;br&gt;有人将KL散度称为KL距离，但事实上，KL散度并不满足距离的概念，因为：&lt;br&gt;1）KL散度不是对称的；&lt;br&gt;2）KL散度不满足三角不等式。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="神经网络" scheme="http://www.lexzhao.top/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="生成式对抗网" scheme="http://www.lexzhao.top/tags/%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91/"/>
    
  </entry>
  
  <entry>
    <title>AccountMerge(UnionFind)</title>
    <link href="http://www.lexzhao.top/2017/12/22/AccountMerge-UnionFind/"/>
    <id>http://www.lexzhao.top/2017/12/22/AccountMerge-UnionFind/</id>
    <published>2017-12-22T15:24:24.000Z</published>
    <updated>2017-12-24T15:39:27.984Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;721. Accounts Merge&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;http://opeygftv2.bkt.clouddn.com/721.JPG&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Leetcode" scheme="http://www.lexzhao.top/tags/Leetcode/"/>
    
      <category term="UnionFind" scheme="http://www.lexzhao.top/tags/UnionFind/"/>
    
  </entry>
  
  <entry>
    <title>Spring源码曲径通幽(1)---Ioc控制反转</title>
    <link href="http://www.lexzhao.top/2017/12/03/Spring%E6%BA%90%E7%A0%81%E6%9B%B2%E5%BE%84%E9%80%9A%E5%B9%BD-1-Ioc%E6%8E%A7%E5%88%B6%E5%8F%8D%E8%BD%AC/"/>
    <id>http://www.lexzhao.top/2017/12/03/Spring源码曲径通幽-1-Ioc控制反转/</id>
    <published>2017-12-03T15:11:20.000Z</published>
    <updated>2017-12-03T15:12:12.746Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Spring" scheme="http://www.lexzhao.top/tags/Spring/"/>
    
      <category term="Java" scheme="http://www.lexzhao.top/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Binary Search总结</title>
    <link href="http://www.lexzhao.top/2017/12/03/Binary-Search%E6%80%BB%E7%BB%93/"/>
    <id>http://www.lexzhao.top/2017/12/03/Binary-Search总结/</id>
    <published>2017-12-03T15:02:36.000Z</published>
    <updated>2017-12-03T15:04:43.527Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Leetcode" scheme="http://www.lexzhao.top/tags/Leetcode/"/>
    
      <category term="Algorithm" scheme="http://www.lexzhao.top/tags/Algorithm/"/>
    
      <category term="BST" scheme="http://www.lexzhao.top/tags/BST/"/>
    
  </entry>
  
  <entry>
    <title>canPartitionKSubsets</title>
    <link href="http://www.lexzhao.top/2017/11/23/canPartitionKSubsets/"/>
    <id>http://www.lexzhao.top/2017/11/23/canPartitionKSubsets/</id>
    <published>2017-11-23T01:54:05.000Z</published>
    <updated>2017-11-23T10:32:54.846Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;拿出以下三道题来进行对比和总结。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;560. Subarray Sum Equals K&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;523. Continuous Subarray Sum&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;209. Minimum Size Subarray Sum&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;713. Subarray Product Less Than K&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Leetcode" scheme="http://www.lexzhao.top/tags/Leetcode/"/>
    
      <category term="Algorithm" scheme="http://www.lexzhao.top/tags/Algorithm/"/>
    
      <category term="DP" scheme="http://www.lexzhao.top/tags/DP/"/>
    
  </entry>
  
  <entry>
    <title>AkkA_OSGi避坑指南</title>
    <link href="http://www.lexzhao.top/2017/11/20/AkkA-OSGi%E9%81%BF%E5%9D%91%E6%8C%87%E5%8D%97/"/>
    <id>http://www.lexzhao.top/2017/11/20/AkkA-OSGi避坑指南/</id>
    <published>2017-11-20T15:47:41.000Z</published>
    <updated>2017-11-22T05:24:53.859Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;实验室项目需要，这段时间一直在搞AkkA框架在OSGi平台上的搭建，由于相关资料少之又少，可以说踩坑无数，于是有了写一篇避坑大全的想法。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://opeygftv2.bkt.clouddn.com/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20171121105638.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="AkkA" scheme="http://www.lexzhao.top/tags/AkkA/"/>
    
      <category term="OSGi" scheme="http://www.lexzhao.top/tags/OSGi/"/>
    
      <category term="scala" scheme="http://www.lexzhao.top/tags/scala/"/>
    
  </entry>
  
  <entry>
    <title>Two Pointer总结</title>
    <link href="http://www.lexzhao.top/2017/11/19/Two-Pointer%E6%80%BB%E7%BB%93/"/>
    <id>http://www.lexzhao.top/2017/11/19/Two-Pointer总结/</id>
    <published>2017-11-19T06:32:47.000Z</published>
    <updated>2017-11-21T08:25:26.100Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;前序&quot;&gt;&lt;a href=&quot;#前序&quot; class=&quot;headerlink&quot; title=&quot;前序&quot;&gt;&lt;/a&gt;&lt;strong&gt;前序&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;Two Pointer应该说之前用到的还是很多的，像一次循环找到链表的中间元素，像快排等等，刚好这两天Leetcode刷到了Two Pointer这一块，借此机会做一个总结。在大多数适合于Two Pointer的场景下，恰当地使用Two pointer可以将复杂度维持在O(N)，特别是一些求解连续子序列相关的问题，Two pointer不失为一种很好地切入点。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="http://www.lexzhao.top/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Leetcode" scheme="http://www.lexzhao.top/tags/Leetcode/"/>
    
      <category term="Algorithm" scheme="http://www.lexzhao.top/tags/Algorithm/"/>
    
  </entry>
  
</feed>
